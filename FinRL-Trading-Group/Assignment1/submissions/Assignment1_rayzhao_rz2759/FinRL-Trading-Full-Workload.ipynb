{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5398 26 Spring: FinRL-Trading Quantitative Trading Strategy Track\n",
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment 1, we want you to :\n",
    "+ Run this ipynb file, which is a simplified FinRL-Trading whole process, and have a basic knowledge of what we will do in this semester\n",
    "+ Design a portfolio using the selected stocks, and learn some fundamental information of quantitative trading (especially stock selection part)\n",
    "+ Implement a full backtest process to verify your strategy's performance using real historical data\n",
    "+ Summarize your result in a very brief research report, and write a `Medium Blog`. Submit your code files onto GitHub repo in a new folder called Assignment1_Name_UNI.\n",
    "    + An example of medium blog: [Applying new LLMs on FinGPT: Fine-tune DeepSeek and Llama3](https://medium.com/p/6ac9198d88b2)\n",
    "\n",
    "Assignment 1 Report Submission Due Day: **Feb 20, 2026**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full `FinRL-Trading` project, please refer to [AI4Finance/FinRL-Trading](https://github.com/AI4Finance-Foundation/FinRL-Trading/tree/master_backup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Prerequisities\n",
    "\n",
    "First, you should decide your stock pool for later selection. Here we recommend you to choose your portfolio from S&P 500 index or NASDAQ 100 index. We have already provided you with their components.\n",
    "\n",
    "Then, you should download stock's daily OHLCV data on [WRDS-Security Daily](https://wrds-www.wharton.upenn.edu/pages/get-data/compustat-capital-iq-standard-poors/compustat/north-america-daily/security-daily/) and quarterly fundamental data on [WRDS-Fundamental Quarterly](https://wrds-www.wharton.upenn.edu/pages/get-data/compustat-capital-iq-standard-poors/compustat/north-america-daily/security-daily/) for later usage.\n",
    "\n",
    "+ Note: Here we highly recommend you to register for a WRDS account which our university has provided for all master students for free. Please follow the instruction below to get a WRDS account:\n",
    "    + https://guides.library.columbia.edu/wrds\n",
    "\n",
    "If you don't have enough storage or want this data file to be loaded faster while doing calculation, you can select these columns below only while querying the WRDS database.\n",
    "+ prccd (Price - Close - Daily)\n",
    "+ prcod (Price - Open - Daily)\n",
    "+ ajexdi (Adjustment Factor (Issue)-Cumulative by Ex-Date)\n",
    "+ tic (Ticker)\n",
    "\n",
    "Since we want you to implement backtest from **Jan 1, 2018** to **Dec 31, 2025**, we suggest you to download all the data during this period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing\n",
    "\n",
    "In this part, we will preprocess all the fundamental data for our Machine Learning algorithms. Please refer to [AI4Finance/FinRL-Trading/data_processor/Step2_preprocess_fundmental_data.py](https://github.com/AI4Finance-Foundation/FinRL-Trading/blob/master_backup/data_processor/Step2_preprocess_fundmental_data.py) for detailed usage.\n",
    "\n",
    "After running this part, you should get a folder with final fundamental ratios split into different industry sections in `xlsx` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime as dt\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fundamental_file, price_file):\n",
    "    \"\"\"\n",
    "    Load fundamental and price data from CSV files.\n",
    "    \n",
    "    Args:\n",
    "        fundamental_file (str): Path to fundamental data CSV file\n",
    "        price_file (str): Path to price data CSV file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (fundamental_df, price_df)\n",
    "    \"\"\"\n",
    "    print(\"Loading data files...\")\n",
    "    \n",
    "    if not os.path.isfile(fundamental_file):\n",
    "        raise FileNotFoundError(f\"Fundamental file {fundamental_file} not found.\")\n",
    "    \n",
    "    if not os.path.isfile(price_file):\n",
    "        raise FileNotFoundError(f\"Price file {price_file} not found.\")\n",
    "    \n",
    "    # Load fundamental data\n",
    "    fund_df = pd.read_csv(fundamental_file)\n",
    "    print(fund_df.head())\n",
    "    \n",
    "    # For price data, only load necessary columns to save memory\n",
    "    print(\"Loading price data (only necessary columns)...\")\n",
    "    price_columns = ['gvkey', 'tic', 'datadate', 'prccd', 'ajexdi']\n",
    "    df_daily_price = pd.read_csv(price_file, usecols=price_columns)\n",
    "    print(df_daily_price.head())\n",
    "    \n",
    "    print(f\"Fundamental data shape: {fund_df.shape}\")\n",
    "    print(f\"Price data shape: {df_daily_price.shape}\")\n",
    "    print(f\"Unique tickers in fundamental data: {len(fund_df.tic.unique())}\")\n",
    "    print(f\"Unique tickers in price data: {len(df_daily_price.tic.unique())}\")\n",
    "    \n",
    "    return fund_df, df_daily_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_trade_dates(fund_df):\n",
    "    \"\"\"\n",
    "    Adjust trade dates to use trading dates instead of quarterly report dates.\n",
    "    \n",
    "    Args:\n",
    "        fund_df (pandas.DataFrame): Fundamental data DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with adjusted trade dates\n",
    "    \"\"\"\n",
    "    print(\"Adjusting trade dates...\")\n",
    "    \n",
    "    # Convert datadate to datetime first, then to integer format\n",
    "    datadate_dt = pd.to_datetime(fund_df['datadate'])\n",
    "\n",
    "    fund_df['tradedate'] = ((datadate_dt.dt.to_period('Q')).dt.end_time.dt.normalize())\n",
    "    fund_df['reportdate'] = fund_df[\"rdq\"]\n",
    "    \n",
    "    return fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adjusted_close(fund_df):\n",
    "    \"\"\"\n",
    "    Calculate adjusted close price.\n",
    "    \n",
    "    Args:\n",
    "        fund_df (pandas.DataFrame): Fundamental data DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with adjusted close price\n",
    "    \"\"\"\n",
    "    print(\"Calculating adjusted close price...\")\n",
    "    fund_df['adj_close_q'] = fund_df.prccq / fund_df.adjex\n",
    "    return fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tickers_and_gvkey(fund_df, df_daily_price):\n",
    "    \"\"\"\n",
    "    Match tickers and gvkey for fundamental and price data.\n",
    "    \n",
    "    Args:\n",
    "        fund_df (pandas.DataFrame): Fundamental data DataFrame\n",
    "        df_daily_price (pandas.DataFrame): Price data DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Filtered fundamental data DataFrame\n",
    "    \"\"\"\n",
    "    print(\"Matching tickers and gvkey...\")\n",
    "    \n",
    "    # Create mapping from ticker to gvkey\n",
    "    tic_to_gvkey = {}\n",
    "    df_daily_groups = list(df_daily_price.groupby('tic'))\n",
    "    \n",
    "    for tic, df_ in df_daily_groups:\n",
    "        tic_to_gvkey[tic] = df_.gvkey.iloc[0]\n",
    "    \n",
    "    print(f\"Original fundamental data shape: {fund_df.shape}\")\n",
    "    \n",
    "    # Filter fundamental data to only include tickers present in price data\n",
    "    fund_df = fund_df[np.isin(fund_df.tic, list(tic_to_gvkey.keys()))]\n",
    "    \n",
    "    print(f\"Filtered fundamental data shape: {fund_df.shape}\")\n",
    "    print(f\"Unique gvkeys: {len(fund_df.gvkey.unique())}\")\n",
    "    \n",
    "    # Add gvkey mapping\n",
    "    fund_df['gvkey'] = [tic_to_gvkey[x] for x in fund_df['tic']]\n",
    "    \n",
    "    return fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next_quarter_returns(fund_df):\n",
    "    \"\"\"\n",
    "    Calculate next quarter's return for each stock.\n",
    "    \n",
    "    Args:\n",
    "        fund_df (pandas.DataFrame): Fundamental data DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with next quarter returns\n",
    "    \"\"\"\n",
    "    print(\"Calculating next quarter returns...\")\n",
    "    \n",
    "    fund_df['date'] = fund_df[\"tradedate\"]\n",
    "    # fund_df['date'] = pd.to_datetime(fund_df['date'], format=\"%Y-%m%d\")\n",
    "    fund_df['date'] = pd.to_datetime(fund_df['date'])\n",
    "    fund_df.drop_duplicates([\"date\", \"gvkey\"], keep='last', inplace=True)\n",
    "    \n",
    "    # Calculate next quarter return for each stock\n",
    "    l_df = list(fund_df.groupby('gvkey'))\n",
    "    for tic, df in l_df:\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        df.sort_values('date')\n",
    "        # Calculate next quarter's return\n",
    "        df['y_return'] = np.log(df['adj_close_q'].shift(-1) / df['adj_close_q'])\n",
    "    \n",
    "    fund_df = pd.concat([x[1] for x in l_df])\n",
    "    \n",
    "    print(f\"Data shape after calculating returns: {fund_df.shape}\")\n",
    "    return fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_basic_ratios(fund_df):\n",
    "    \"\"\"\n",
    "    Calculate basic financial ratios (PE, PS, PB).\n",
    "    \n",
    "    Args:\n",
    "        fund_df (pandas.DataFrame): Fundamental data DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with basic ratios\n",
    "    \"\"\"\n",
    "    print(\"Calculating basic financial ratios...\")\n",
    "    \n",
    "    fund_df['pe'] = fund_df.prccq / fund_df.epspxq\n",
    "    fund_df['ps'] = fund_df.prccq / (fund_df.revtq / fund_df.cshoq)\n",
    "    fund_df['pb'] = fund_df.prccq / ((fund_df.atq - fund_df.ltq) / fund_df.cshoq)\n",
    "    \n",
    "    return fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(fund_df):\n",
    "    \"\"\"\n",
    "    Select relevant columns for analysis.\n",
    "    \n",
    "    Args:\n",
    "        fund_df (pandas.DataFrame): Fundamental data DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with selected columns\n",
    "    \"\"\"\n",
    "    print(\"Selecting relevant columns...\")\n",
    "    \n",
    "    items = [\n",
    "        'date', 'gvkey', 'tic', 'gsector',\n",
    "        'oiadpq', 'revtq', 'niq', 'atq', 'teqq', 'epspiy', 'ceqq', 'cshoq', 'dvpspq',\n",
    "        'actq', 'lctq', 'cheq', 'rectq', 'cogsq', 'invtq', 'apq', 'dlttq', 'dlcq', 'ltq',\n",
    "        'pe', 'ps', 'pb', 'adj_close_q', 'y_return', 'reportdate'\n",
    "    ]\n",
    "    \n",
    "    fund_data = fund_df[items]\n",
    "    \n",
    "    # Rename columns for readability\n",
    "    fund_data = fund_data.rename(columns={\n",
    "        'oiadpq': 'op_inc_q',\n",
    "        'revtq': 'rev_q',\n",
    "        'niq': 'net_inc_q',\n",
    "        'atq': 'tot_assets',\n",
    "        'teqq': 'sh_equity',\n",
    "        'epspiy': 'eps_incl_ex',\n",
    "        'ceqq': 'com_eq',\n",
    "        'cshoq': 'sh_outstanding',\n",
    "        'dvpspq': 'div_per_sh',\n",
    "        'actq': 'cur_assets',\n",
    "        'lctq': 'cur_liabilities',\n",
    "        'cheq': 'cash_eq',\n",
    "        'rectq': 'receivables',\n",
    "        'cogsq': 'cogs_q',\n",
    "        'invtq': 'inventories',\n",
    "        'apq': 'payables',\n",
    "        'dlttq': 'long_debt',\n",
    "        'dlcq': 'short_debt',\n",
    "        'ltq': 'tot_liabilities'\n",
    "    })\n",
    "    \n",
    "    return fund_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_financial_ratios(fund_data):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive financial ratios.\n",
    "    \n",
    "    Args:\n",
    "        fund_data (pandas.DataFrame): Fundamental data DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with all financial ratios\n",
    "    \"\"\"\n",
    "    print(\"Calculating comprehensive financial ratios...\")\n",
    "    \n",
    "    # Set data type to series\n",
    "    date = fund_data['date'].to_frame('date').reset_index(drop=True)\n",
    "    reportdate = fund_data['reportdate'].to_frame('reportdate').reset_index(drop=True)\n",
    "    tic = fund_data['tic'].to_frame('tic').reset_index(drop=True)\n",
    "    gvkey = fund_data['gvkey'].to_frame('gvkey').reset_index(drop=True)\n",
    "    adj_close_q = fund_data['adj_close_q'].to_frame('adj_close_q').reset_index(drop=True)\n",
    "    y_return = fund_data['y_return'].to_frame('y_return').reset_index(drop=True)\n",
    "    gsector = fund_data['gsector'].to_frame('gsector').reset_index(drop=True)\n",
    "    pe = fund_data['pe'].to_frame('pe').reset_index(drop=True)\n",
    "    ps = fund_data['ps'].to_frame('ps').reset_index(drop=True)\n",
    "    pb = fund_data['pb'].to_frame('pb').reset_index(drop=True)\n",
    "    \n",
    "    # Profitability ratios\n",
    "    print(\"  Calculating profitability ratios...\")\n",
    "    \n",
    "    # Operating Margin\n",
    "    OPM = pd.Series(np.empty(fund_data.shape[0], dtype=object), name='OPM')\n",
    "    for i in range(0, fund_data.shape[0]):\n",
    "        if i-3 < 0:\n",
    "            OPM[i] = np.nan\n",
    "        elif fund_data.iloc[i, 1] != fund_data.iloc[i-3, 1]:\n",
    "            OPM.iloc[i] = np.nan\n",
    "        else:\n",
    "            OPM.iloc[i] = np.sum(fund_data['op_inc_q'].iloc[i-3:i]) / np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
    "    OPM = pd.Series(OPM).to_frame().reset_index(drop=True)\n",
    "    \n",
    "    # Net Profit Margin\n",
    "    NPM = pd.Series(np.empty(fund_data.shape[0], dtype=object), name='NPM')\n",
    "    for i in range(0, fund_data.shape[0]):\n",
    "        if i-3 < 0:\n",
    "            NPM[i] = np.nan\n",
    "        elif fund_data.iloc[i, 1] != fund_data.iloc[i-3, 1]:\n",
    "            NPM.iloc[i] = np.nan\n",
    "        else:\n",
    "            NPM.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i]) / np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
    "    NPM = pd.Series(NPM).to_frame().reset_index(drop=True)\n",
    "    \n",
    "    # Return On Assets\n",
    "    ROA = pd.Series(np.empty(fund_data.shape[0], dtype=object), name='ROA')\n",
    "    for i in range(0, fund_data.shape[0]):\n",
    "        if i-3 < 0:\n",
    "            ROA[i] = np.nan\n",
    "        elif fund_data.iloc[i, 1] != fund_data.iloc[i-3, 1]:\n",
    "            ROA.iloc[i] = np.nan\n",
    "        else:\n",
    "            ROA.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i]) / fund_data['tot_assets'].iloc[i]\n",
    "    ROA = pd.Series(ROA).to_frame().reset_index(drop=True)\n",
    "    \n",
    "    # Return on Equity\n",
    "    ROE = pd.Series(np.empty(fund_data.shape[0], dtype=object), name='ROE')\n",
    "    for i in range(0, fund_data.shape[0]):\n",
    "        if i-3 < 0:\n",
    "            ROE[i] = np.nan\n",
    "        elif fund_data.iloc[i, 1] != fund_data.iloc[i-3, 1]:\n",
    "            ROE.iloc[i] = np.nan\n",
    "        else:\n",
    "            ROE.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i]) / fund_data['sh_equity'].iloc[i]\n",
    "    ROE = pd.Series(ROE).to_frame().reset_index(drop=True)\n",
    "    \n",
    "    # Per share items\n",
    "    EPS = fund_data['eps_incl_ex'].to_frame('EPS').reset_index(drop=True)\n",
    "    BPS = (fund_data['com_eq'] / fund_data['sh_outstanding']).to_frame('BPS').reset_index(drop=True)\n",
    "    DPS = fund_data['div_per_sh'].to_frame('DPS').reset_index(drop=True)\n",
    "    \n",
    "    # Liquidity ratios\n",
    "    print(\"  Calculating liquidity ratios...\")\n",
    "    cur_ratio = (fund_data['cur_assets'] / fund_data['cur_liabilities']).to_frame('cur_ratio').reset_index(drop=True)\n",
    "    quick_ratio = ((fund_data['cash_eq'] + fund_data['receivables']) / fund_data['cur_liabilities']).to_frame('quick_ratio').reset_index(drop=True)\n",
    "    cash_ratio = (fund_data['cash_eq'] / fund_data['cur_liabilities']).to_frame('cash_ratio').reset_index(drop=True)\n",
    "    \n",
    "    # Efficiency ratios\n",
    "    print(\"  Calculating efficiency ratios...\")\n",
    "    \n",
    "    # Inventory turnover ratio\n",
    "    inv_turnover = pd.Series(np.empty(fund_data.shape[0], dtype=object), name='inv_turnover')\n",
    "    for i in range(0, fund_data.shape[0]):\n",
    "        if i-3 < 0:\n",
    "            inv_turnover[i] = np.nan\n",
    "        elif fund_data.iloc[i, 1] != fund_data.iloc[i-3, 1]:\n",
    "            inv_turnover.iloc[i] = np.nan\n",
    "        else:\n",
    "            inv_turnover.iloc[i] = np.sum(fund_data['cogs_q'].iloc[i-3:i]) / fund_data['inventories'].iloc[i]\n",
    "    inv_turnover = pd.Series(inv_turnover).to_frame().reset_index(drop=True)\n",
    "    \n",
    "    # Receivables turnover ratio\n",
    "    acc_rec_turnover = pd.Series(np.empty(fund_data.shape[0], dtype=object), name='acc_rec_turnover')\n",
    "    for i in range(0, fund_data.shape[0]):\n",
    "        if i-3 < 0:\n",
    "            acc_rec_turnover[i] = np.nan\n",
    "        elif fund_data.iloc[i, 1] != fund_data.iloc[i-3, 1]:\n",
    "            acc_rec_turnover.iloc[i] = np.nan\n",
    "        else:\n",
    "            acc_rec_turnover.iloc[i] = np.sum(fund_data['rev_q'].iloc[i-3:i]) / fund_data['receivables'].iloc[i]\n",
    "    acc_rec_turnover = pd.Series(acc_rec_turnover).to_frame().reset_index(drop=True)\n",
    "    \n",
    "    # Payable turnover ratio\n",
    "    acc_pay_turnover = pd.Series(np.empty(fund_data.shape[0], dtype=object), name='acc_pay_turnover')\n",
    "    for i in range(0, fund_data.shape[0]):\n",
    "        if i-3 < 0:\n",
    "            acc_pay_turnover[i] = np.nan\n",
    "        elif fund_data.iloc[i, 1] != fund_data.iloc[i-3, 1]:\n",
    "            acc_pay_turnover.iloc[i] = np.nan\n",
    "        else:\n",
    "            acc_pay_turnover.iloc[i] = np.sum(fund_data['cogs_q'].iloc[i-3:i]) / fund_data['payables'].iloc[i]\n",
    "    acc_pay_turnover = pd.Series(acc_pay_turnover).to_frame().reset_index(drop=True)\n",
    "    \n",
    "    # Leverage ratios\n",
    "    print(\"  Calculating leverage ratios...\")\n",
    "    debt_ratio = (fund_data['tot_liabilities'] / fund_data['tot_assets']).to_frame('debt_ratio').reset_index(drop=True)\n",
    "    debt_to_equity = (fund_data['tot_liabilities'] / fund_data['sh_equity']).to_frame('debt_to_equity').reset_index(drop=True)\n",
    "    \n",
    "    # Create final ratios dataframe\n",
    "    ratios = pd.concat([\n",
    "        date, gvkey, tic, gsector, adj_close_q, y_return,\n",
    "        OPM, NPM, ROA, ROE, EPS, BPS, DPS,\n",
    "        cur_ratio, quick_ratio, cash_ratio, inv_turnover, acc_rec_turnover, acc_pay_turnover,\n",
    "        debt_ratio, debt_to_equity, pe, ps, pb, reportdate\n",
    "    ], axis=1).reset_index(drop=True)\n",
    "    \n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(ratios):\n",
    "    \"\"\"\n",
    "    Handle missing values and infinite values in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        ratios (pandas.DataFrame): DataFrame with financial ratios\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    print(\"Handling missing values...\")\n",
    "    \n",
    "    # Replace NAs and infinite values with zero initially\n",
    "    final_ratios = ratios.copy()\n",
    "    final_ratios = final_ratios.fillna(0)\n",
    "    final_ratios = final_ratios.replace(np.inf, 0)\n",
    "    \n",
    "    # Define financial features columns\n",
    "    features_column_financial = [\n",
    "        'OPM', 'NPM', 'ROA', 'ROE', 'EPS', 'BPS', 'DPS', 'cur_ratio',\n",
    "        'quick_ratio', 'cash_ratio', 'inv_turnover', 'acc_rec_turnover',\n",
    "        'acc_pay_turnover', 'debt_ratio', 'debt_to_equity', 'pe', 'ps', 'pb'\n",
    "    ]\n",
    "    \n",
    "    # Remove rows with zero adjusted close price\n",
    "    final_ratios = final_ratios.drop(list(final_ratios[final_ratios.adj_close_q == 0].index)).reset_index(drop=True)\n",
    "    \n",
    "    # Convert to numeric and handle invalid values\n",
    "    final_ratios['y_return'] = pd.to_numeric(final_ratios['y_return'], errors='coerce')\n",
    "    for col in features_column_financial:\n",
    "        if col in final_ratios.columns:\n",
    "            final_ratios[col] = pd.to_numeric(final_ratios[col], errors='coerce')\n",
    "    \n",
    "    final_ratios['y_return'].replace([np.nan, np.inf, -np.inf], np.nan, inplace=True)\n",
    "    final_ratios[features_column_financial].replace([np.nan, np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Remove columns with too many invalid values\n",
    "    dropped_col = []\n",
    "    for col in features_column_financial:\n",
    "        if col in final_ratios.columns and np.any(~np.isfinite(final_ratios[col])):\n",
    "            final_ratios.drop(columns=[col], axis=1, inplace=True)\n",
    "            dropped_col.append(col)\n",
    "    \n",
    "    # Remove rows with any missing values\n",
    "    final_ratios.dropna(axis=0, inplace=True)\n",
    "    final_ratios = final_ratios[final_ratios[\"reportdate\"].ne(0)]  \n",
    "    final_ratios = final_ratios.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Dropped columns: {dropped_col}\")\n",
    "    print(f\"Final data shape: {final_ratios.shape}\")\n",
    "    \n",
    "    return final_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(final_ratios, output_dir=\"outputs\", include_sector0=False):\n",
    "    \"\"\"\n",
    "    Save the processed data to files.\n",
    "    \n",
    "    Args:\n",
    "        final_ratios (pandas.DataFrame): Final processed data\n",
    "        output_dir (str): Output directory\n",
    "        include_sector0 (bool): Whether to include sector 0 in sector-specific files (default: False)\n",
    "    \"\"\"\n",
    "    print(\"Saving results...\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Format date column\n",
    "    # final_ratios.date = final_ratios.date.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # Save main results\n",
    "    main_output_file = os.path.join(output_dir, 'final_ratios.csv')\n",
    "    final_ratios.to_csv(main_output_file, index=False)\n",
    "    print(f\"Main results saved to: {main_output_file}\")\n",
    "    \n",
    "    # Save by sector\n",
    "    print(\"Saving sector-specific files...\")\n",
    "    sector_count = 0\n",
    "    for sec, df_ in list(final_ratios.groupby('gsector')):\n",
    "        # Skip sector 0 unless explicitly included\n",
    "        if sec == 0 and not include_sector0:\n",
    "            print(f\"  Skipping Sector 0: {len(df_)} records (stocks with missing sector information)\")\n",
    "            continue\n",
    "        \n",
    "        sector_file = os.path.join(output_dir, f\"sector{int(sec)}.xlsx\")\n",
    "        df_.to_excel(sector_file, index=False)\n",
    "        print(f\"  Sector {int(sec)}: {sector_file} ({len(df_)} records)\")\n",
    "        sector_count += 1\n",
    "    \n",
    "    print(f\"  Total sectors saved: {sector_count}\")\n",
    "    \n",
    "    return main_output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _find_assignment_root(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    candidates = []\n",
    "    for base in [start, *start.parents]:\n",
    "        candidates.extend([\n",
    "            base,\n",
    "            base / \"Assignment1_rayzhao_rz2759\",\n",
    "            base / \"Assignment1\" / \"submissions\" / \"Assignment1_rayzhao_rz2759\",\n",
    "            base / \"FinRL-Trading-Group\" / \"Assignment1_rayzhao_rz2759\",\n",
    "            base / \"FinRL-Trading-Group\" / \"Assignment1\" / \"submissions\" / \"Assignment1_rayzhao_rz2759\",\n",
    "        ])\n",
    "\n",
    "    seen = set()\n",
    "    for cand in candidates:\n",
    "        cand = cand.resolve()\n",
    "        key = str(cand).lower()\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        if (cand / \"nasdaq_fundamental.csv\").exists() and (cand / \"nasdaq_stock.csv\").exists():\n",
    "            return cand\n",
    "\n",
    "    raise FileNotFoundError(\"Cannot locate assignment root. Please run notebook from repo workspace.\")\n",
    "\n",
    "\n",
    "assignment_root = _find_assignment_root()\n",
    "\n",
    "Stock_Index_fundation_file = str(assignment_root / \"nasdaq_fundamental.csv\") ### Path of fundamental data\n",
    "Stock_Index_price_file = str(assignment_root / \"nasdaq_stock.csv\") ### Path of daily price data\n",
    "output_dir = str(assignment_root / \"outputs\") ### Output directory for part 1\n",
    "include_sector0 = False\n",
    "\n",
    "print(f\"Using assignment root: {assignment_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "S&P 500 Fundamental Data Preprocessing Tool\n",
      "================================================================================\n",
      "Fundamental file: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/nasdaq_fundamental.csv\n",
      "Price file: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/nasdaq_stock.csv\n",
      "Output directory: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\n",
      "Include sector 0 in sector files: False\n",
      "--------------------------------------------------------------------------------\n",
      "Loading data files...\n",
      "  costat curcdq datafmt indfmt consol   tic    datadate  gvkey  gsector  \\\n",
      "0      A    USD     STD   INDL      C  AAPL  2015-03-31   1690       45   \n",
      "1      A    USD     STD   INDL      C  AAPL  2015-06-30   1690       45   \n",
      "2      A    USD     STD   INDL      C  AAPL  2015-09-30   1690       45   \n",
      "3      A    USD     STD   INDL      C  AAPL  2015-12-31   1690       45   \n",
      "4      A    USD     STD   INDL      C  AAPL  2016-03-31   1690       45   \n",
      "\n",
      "          rdq  ...       ltq      niq   oiadpq    rectq    revtq      teqq  \\\n",
      "0  2015-04-27  ...  132188.0  13569.0  18278.0  18164.0  58010.0  129006.0   \n",
      "1  2015-07-21  ...  147474.0  10677.0  14083.0  19907.0  49605.0  125677.0   \n",
      "2  2015-10-27  ...  171124.0  11124.0  14623.0  30343.0  51501.0  119355.0   \n",
      "3  2016-01-26  ...  165017.0  18361.0  23623.0  24621.0  75324.0  128267.0   \n",
      "4  2016-04-26  ...  174820.0  10516.0  13987.0  19824.0  50557.0  130457.0   \n",
      "\n",
      "   epspiy  adjex  dvpspq    prccq  \n",
      "0    5.43    4.0    0.47  124.430  \n",
      "1    7.30    4.0    0.52  125.425  \n",
      "2    9.28    4.0    0.52  110.300  \n",
      "3    3.30    4.0    0.52  105.260  \n",
      "4    5.22    4.0    0.52  108.990  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Loading price data (only necessary columns)...\n",
      "   tic    datadate  ajexdi  prccd  gvkey\n",
      "0  AMD  2010-01-04     1.0   9.70   1161\n",
      "1  AMD  2010-01-05     1.0   9.71   1161\n",
      "2  AMD  2010-01-06     1.0   9.57   1161\n",
      "3  AMD  2010-01-07     1.0   9.47   1161\n",
      "4  AMD  2010-01-08     1.0   9.43   1161\n",
      "Fundamental data shape: (4219, 32)\n",
      "Price data shape: (359067, 5)\n",
      "Unique tickers in fundamental data: 100\n",
      "Unique tickers in price data: 101\n",
      "Adjusting trade dates...\n",
      "Calculating adjusted close price...\n",
      "Matching tickers and gvkey...\n",
      "Original fundamental data shape: (4219, 35)\n",
      "Filtered fundamental data shape: (4219, 35)\n",
      "Unique gvkeys: 100\n",
      "Calculating next quarter returns...\n",
      "Data shape after calculating returns: (4219, 37)\n",
      "Calculating basic financial ratios...\n",
      "Selecting relevant columns...\n",
      "Calculating comprehensive financial ratios...\n",
      "  Calculating profitability ratios...\n",
      "  Calculating liquidity ratios...\n",
      "  Calculating efficiency ratios...\n",
      "  Calculating leverage ratios...\n",
      "Handling missing values...\n",
      "Dropped columns: []\n",
      "Final data shape: (4055, 25)\n",
      "Saving results...\n",
      "Main results saved to: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv\n",
      "Saving sector-specific files...\n",
      "  Sector 10: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector10.xlsx (77 records)\n",
      "  Sector 15: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector15.xlsx (44 records)\n",
      "  Sector 20: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector20.xlsx (526 records)\n",
      "  Sector 25: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector25.xlsx (464 records)\n",
      "  Sector 30: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector30.xlsx (276 records)\n",
      "  Sector 35: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector35.xlsx (408 records)\n",
      "  Sector 40: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector40.xlsx (42 records)\n",
      "  Sector 45: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector45.xlsx (1596 records)\n",
      "  Sector 50: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector50.xlsx (432 records)\n",
      "  Sector 55: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector55.xlsx (147 records)\n",
      "  Sector 60: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector60.xlsx (43 records)\n",
      "  Total sectors saved: 11\n",
      "\n",
      "================================================================================\n",
      "Processing completed successfully!\n",
      "Final dataset shape: (4055, 25)\n",
      "Output saved to: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"S&P 500 Fundamental Data Preprocessing Tool\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Fundamental file: {Stock_Index_fundation_file}\")\n",
    "print(f\"Price file: {Stock_Index_price_file}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Include sector 0 in sector files: {include_sector0}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Load data\n",
    "fund_df, df_daily_price = load_data(Stock_Index_fundation_file, Stock_Index_price_file)\n",
    "\n",
    "# Process data\n",
    "fund_df = adjust_trade_dates(fund_df)\n",
    "fund_df = calculate_adjusted_close(fund_df)\n",
    "fund_df = match_tickers_and_gvkey(fund_df, df_daily_price)\n",
    "fund_df = calculate_next_quarter_returns(fund_df)\n",
    "fund_df = calculate_basic_ratios(fund_df)\n",
    "\n",
    "# Select and process columns\n",
    "fund_data = select_columns(fund_df)\n",
    "\n",
    "# Calculate financial ratios\n",
    "ratios = calculate_financial_ratios(fund_data)\n",
    "\n",
    "# Handle missing values\n",
    "final_ratios = handle_missing_values(ratios)\n",
    "\n",
    "# Save results\n",
    "output_file = save_results(final_ratios, output_dir, include_sector0)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Processing completed successfully!\")\n",
    "print(f\"Final dataset shape: {final_ratios.shape}\")\n",
    "print(f\"Output saved to: {output_file}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stock Selection\n",
    "\n",
    "In this part, we will use processed fundamental data to predict stocks' future return.\n",
    "\n",
    "To be specific, we will use 3 different machine learning algorithms (Random Forest, LightGBM, XGBoost) to predict next quarter's performance. Instead of setting a specific date to calculate all the future returns, here we optimized to predict dynamically. While there is a new report published, we can immediately renew its latest prediction. Then, we choose stocks with top k% (you can adjust this rate by yourself) predicted return as our portfolio.\n",
    "\n",
    "For details, please refer to `fundamental_run_model.py` and `ml_model.py`. Also, we recommend you to try DRL stock selection and reallocation algorithm in [AI4Finance/FinRL-Trading/fundamental_portfolio_drl.py](https://github.com/AI4Finance-Foundation/FinRL-Trading/blob/master_backup/fundamental_portfolio_drl.py).\n",
    "\n",
    "After running this part, you should get a csv file contains all your portfolio's components history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(directory_path):\n",
    "    \"\"\"\n",
    "    Create directory if it doesn't exist\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Directory path\n",
    "    \"\"\"\n",
    "    path = Path(directory_path)\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"✓ Created directory: {directory_path}\")\n",
    "    else:\n",
    "        print(f\"✓ Directory already exists: {directory_path}\")\n",
    "\n",
    "def quarter_ffill(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qkey = df.index.to_period(\"Q\")\n",
    "    df = df.groupby(qkey).ffill()\n",
    "    return df\n",
    "\n",
    "def quarter_reportday_ffill(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    full_idx = pd.bdate_range(df.index.min(), df.index.max())\n",
    "\n",
    "    out = df.reindex(full_idx)\n",
    "    out = out.sort_index().copy()\n",
    "    idx = out.index\n",
    "    for col in out.columns:\n",
    "        s = out[col]\n",
    "        if not s.notna().any():\n",
    "            continue\n",
    "        dates = s.dropna().index\n",
    "        for i, t0 in enumerate(dates):\n",
    "            val = s.at[t0]\n",
    "            t1 = dates[i + 1] if i + 1 < len(dates) else None\n",
    "            cap = (t0.to_period('Q') + 1).end_time.normalize()\n",
    "            mask = (idx > t0) & (idx < (t1 if t1 and t1 <= cap else cap + pd.Timedelta('1ns')))\n",
    "            out.loc[mask, col] = val\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stock_selection(data_path, output_path):\n",
    "    \"\"\"\n",
    "    Run stock selection model\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Input sector files directory\n",
    "        output_path (str): Output directory\n",
    "    \"\"\"\n",
    "    # Define sector range\n",
    "    sectors = range(10, 65, 5)\n",
    "    \n",
    "    # Set data directory path\n",
    "    DATA_DIR = data_path\n",
    "    FUNDAMENTAL_FILE = os.path.join(DATA_DIR, \"final_ratios.csv\")\n",
    "\n",
    "    # Trade-date controls for Part 2 output window\n",
    "    FIRST_TRADE_INDEX = int(globals().get(\"FIRST_TRADE_INDEX\", 12))  # 2018-03-31 in current data\n",
    "    TESTING_WINDOW = int(globals().get(\"TESTING_WINDOW\", 4))\n",
    "    RESULT_START_DATE = pd.Timestamp(globals().get(\"RESULT_START_DATE\", \"2018-01-01\"))\n",
    "    RESULT_END_DATE = pd.Timestamp(globals().get(\"RESULT_END_DATE\", \"2025-12-31\"))\n",
    "    \n",
    "    print(f\"Using data directory: {DATA_DIR}\")\n",
    "    print(f\"Fundamental data file: {FUNDAMENTAL_FILE}\")\n",
    "    print(f\"Output directory: {output_path}\")\n",
    "    print(f\"Sector range: {list(sectors)}\")\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(FUNDAMENTAL_FILE):\n",
    "        print(f\"Error: Fundamental data file does not exist: {FUNDAMENTAL_FILE}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Create output directory\n",
    "    create_directory_if_not_exists(output_path)\n",
    "    \n",
    "    # gvkey is unique identifier\n",
    "    df_dict = {'tic': [], 'predicted_return': [], 'trade_date': []}\n",
    "    \n",
    "    # ===== Run stock selection for all sectors in my_outputs directory =====\n",
    "    start = time.time()\n",
    "    print(\"\\nStarting stock selection model for all sectors...\")\n",
    "\n",
    "    df_all = pd.DataFrame()\n",
    "    \n",
    "    for sector in sectors:\n",
    "        sector_file = os.path.join(DATA_DIR, f\"sector{sector}.xlsx\")\n",
    "        print(f\"\\nProcessing sector{sector}...\")\n",
    "        \n",
    "        # Check if sector file exists\n",
    "        if not os.path.exists(sector_file):\n",
    "            print(f\"   Warning: Sector file does not exist, skipping: {sector_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Run model training - using files from specified directory\n",
    "        cmd = (\n",
    "            f\"{sys.executable} fundamental_run_model.py \"\n",
    "            f\"-sector_name sector{sector} -tic_column tic \"\n",
    "            f\"-fundamental {FUNDAMENTAL_FILE} -sector {sector_file} \"\n",
    "            f\"-first_trade_index {FIRST_TRADE_INDEX} -testing_window {TESTING_WINDOW}\"\n",
    "        )\n",
    "        print(f\"Executing command: {cmd}\")\n",
    "        \n",
    "        result = os.system(cmd)\n",
    "        if result != 0:\n",
    "            print(f\" sector{sector} model training failed\")\n",
    "            continue\n",
    "        \n",
    "        # Read prediction results\n",
    "        result_file = f\"results/sector{sector}/df_predict_best.csv\"\n",
    "        if not os.path.exists(result_file):\n",
    "            print(f\" Prediction result file does not exist: {result_file}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(result_file, index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        print(f\"  Reading prediction results: {df.shape[0]} dates, {df.shape[1]} stocks\")\n",
    "        df = quarter_reportday_ffill(df)\n",
    "        df_all = pd.concat([df_all, df], axis=1)\n",
    "        print(f\" sector{sector} processing completed\")\n",
    "\n",
    "    for idx in df_all.index:\n",
    "        predicted_return = df_all.loc[idx]\n",
    "        ### Choose top 25% stocks, or you can adjust by yourself\n",
    "        btm_q = predicted_return.quantile(0.75)\n",
    "        # top_q = predicted_return.quantile(1)\n",
    "        predicted_return = predicted_return[predicted_return >= btm_q]\n",
    "        # predicted_return = predicted_return[(predicted_return >= btm_q) & (predicted_return <= top_q)]\n",
    "        for tic in predicted_return.index:\n",
    "            df_dict[\"tic\"].append(tic)\n",
    "            df_dict[\"predicted_return\"].append(predicted_return[tic])\n",
    "            df_dict[\"trade_date\"].append(idx)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"\\nTotal time: {(end-start)/60:.2f} minutes\")\n",
    "    print(f\"Processing completed! Total records: {len(df_dict['tic'])}\")\n",
    "    \n",
    "    # Create result DataFrame\n",
    "    df_result = pd.DataFrame(df_dict)\n",
    "    if len(df_result) > 0:\n",
    "        df_result[\"trade_date\"] = pd.to_datetime(df_result[\"trade_date\"])\n",
    "        df_result = df_result[(df_result[\"trade_date\"] >= RESULT_START_DATE) & (df_result[\"trade_date\"] <= RESULT_END_DATE)]\n",
    "\n",
    "    \n",
    "    # Save results to CSV file\n",
    "    output_file = os.path.join(output_path, \"stock_selected.csv\")\n",
    "    df_result.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    # Display result statistics\n",
    "    if len(df_result) > 0:\n",
    "        print(f\"\\nResult statistics:\")\n",
    "        print(f\"  Total records: {len(df_result)}\")\n",
    "        print(f\"  Unique stocks: {df_result['tic'].nunique()}\")\n",
    "        print(f\"  Date range: {df_result['trade_date'].min()} to {df_result['trade_date'].max()}\")\n",
    "        print(f\"  Predicted return range: {df_result['predicted_return'].min():.4f} to {df_result['predicted_return'].max():.4f}\")\n",
    "    else:\n",
    "        print(\"\\nWarning: No stock selection results generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if \"assignment_root\" not in locals() or not (Path(str(assignment_root)) / \"nasdaq_stock.csv\").exists():\n",
    "    # Reuse the same root-discovery rule if this cell is run independently.\n",
    "    def _find_assignment_root(start: Path | None = None) -> Path:\n",
    "        start = (start or Path.cwd()).resolve()\n",
    "        candidates = []\n",
    "        for base in [start, *start.parents]:\n",
    "            candidates.extend([\n",
    "                base,\n",
    "                base / \"Assignment1_rayzhao_rz2759\",\n",
    "                base / \"Assignment1\" / \"submissions\" / \"Assignment1_rayzhao_rz2759\",\n",
    "                base / \"FinRL-Trading-Group\" / \"Assignment1_rayzhao_rz2759\",\n",
    "                base / \"FinRL-Trading-Group\" / \"Assignment1\" / \"submissions\" / \"Assignment1_rayzhao_rz2759\",\n",
    "            ])\n",
    "        seen = set()\n",
    "        for cand in candidates:\n",
    "            cand = cand.resolve()\n",
    "            key = str(cand).lower()\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            if (cand / \"nasdaq_fundamental.csv\").exists() and (cand / \"nasdaq_stock.csv\").exists():\n",
    "                return cand\n",
    "        raise FileNotFoundError(\"Cannot locate assignment root.\")\n",
    "\n",
    "    assignment_root = _find_assignment_root()\n",
    "else:\n",
    "    assignment_root = Path(str(assignment_root)).resolve()\n",
    "\n",
    "if \"output_dir\" not in locals() or not output_dir:\n",
    "    output_dir = str(assignment_root / \"outputs\")\n",
    "\n",
    "data_path = output_dir ### Path of fundamental outputs from part 1\n",
    "output_path_step2 = str(assignment_root / \"outputs_step2\") ### Output directory for part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data directory: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\n",
      "Fundamental data file: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv\n",
      "Output directory: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs_step2\n",
      "Sector range: [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
      "✓ Created directory: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs_step2\n",
      "\n",
      "Starting stock selection model for all sectors...\n",
      "\n",
      "Processing sector10...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector10 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector10.xlsx\n",
      "  Reading prediction results: 47 dates, 2 stocks\n",
      " sector10 processing completed\n",
      "\n",
      "Processing sector15...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector15 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector15.xlsx\n",
      "  Reading prediction results: 24 dates, 1 stocks\n",
      " sector15 processing completed\n",
      "\n",
      "Processing sector20...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector20 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector20.xlsx\n",
      "  Reading prediction results: 248 dates, 12 stocks\n",
      " sector20 processing completed\n",
      "\n",
      "Processing sector25...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector25 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector25.xlsx\n",
      "  Reading prediction results: 222 dates, 12 stocks\n",
      " sector25 processing completed\n",
      "\n",
      "Processing sector30...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector30 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector30.xlsx\n",
      "  Reading prediction results: 131 dates, 7 stocks\n",
      " sector30 processing completed\n",
      "\n",
      "Processing sector35...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector35 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector35.xlsx\n",
      "  Reading prediction results: 165 dates, 10 stocks\n",
      " sector35 processing completed\n",
      "\n",
      "Processing sector40...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector40 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector40.xlsx\n",
      "  Reading prediction results: 22 dates, 1 stocks\n",
      " sector40 processing completed\n",
      "\n",
      "Processing sector45...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector45 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector45.xlsx\n",
      "  Reading prediction results: 530 dates, 40 stocks\n",
      " sector45 processing completed\n",
      "\n",
      "Processing sector50...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector50 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector50.xlsx\n",
      "  Reading prediction results: 189 dates, 10 stocks\n",
      " sector50 processing completed\n",
      "\n",
      "Processing sector55...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector55 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector55.xlsx\n",
      "  Reading prediction results: 77 dates, 4 stocks\n",
      " sector55 processing completed\n",
      "\n",
      "Processing sector60...\n",
      "Executing command: d:\\python_library_envs\\stat5398\\python.exe fundamental_run_model.py -sector_name sector60 -tic_column tic -fundamental D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\final_ratios.csv -sector D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs\\sector60.xlsx\n",
      "  Reading prediction results: 23 dates, 1 stocks\n",
      " sector60 processing completed\n",
      "\n",
      "Total time: 81.09 minutes\n",
      "Processing completed! Total records: 40497\n",
      "Results saved to: D:/vs_code_project/finrl/STAT-GR5398-Spring-2026/FinRL-Trading-Group/Assignment1_rayzhao_rz2759/outputs_step2\\stock_selected.csv\n",
      "\n",
      "Result statistics:\n",
      "  Total records: 40497\n",
      "  Unique stocks: 78\n",
      "  Date range: 2020-02-12 00:00:00 to 2026-02-12 00:00:00\n",
      "  Predicted return range: 0.0364 to 0.2657\n"
     ]
    }
   ],
   "source": [
    "run_stock_selection(data_path, output_path_step2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Backtest\n",
    "\n",
    "In this part, you should use your result from part 2 to design a quantitative trading strategy. Your portfolio's performance should **beat S&P 500** during all the time.\n",
    "\n",
    "Here we provide you with a simple strategy: equal weight portfolio with buy & hold strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Strategy Portfolio Construction (Thin Wrapper -> strategy_framework) ============\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def _find_assignment_root(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    candidates = []\n",
    "    for base in [start, *start.parents]:\n",
    "        candidates.extend([\n",
    "            base,\n",
    "            base / \"Assignment1_rayzhao_rz2759\",\n",
    "            base / \"Assignment1\" / \"submissions\" / \"Assignment1_rayzhao_rz2759\",\n",
    "            base / \"FinRL-Trading-Group\" / \"Assignment1_rayzhao_rz2759\",\n",
    "            base / \"FinRL-Trading-Group\" / \"Assignment1\" / \"submissions\" / \"Assignment1_rayzhao_rz2759\",\n",
    "        ])\n",
    "\n",
    "    seen = set()\n",
    "    for cand in candidates:\n",
    "        cand = cand.resolve()\n",
    "        key = str(cand).lower()\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        if (cand / \"nasdaq_stock.csv\").exists() and (cand / \"fundamental_run_model.py\").exists():\n",
    "            return cand\n",
    "\n",
    "    raise FileNotFoundError(\"Cannot locate assignment root for Part 3.\")\n",
    "\n",
    "\n",
    "if \"assignment_root\" in locals():\n",
    "    candidate_root = Path(str(assignment_root)).resolve()\n",
    "    if (candidate_root / \"nasdaq_stock.csv\").exists() and (candidate_root / \"fundamental_run_model.py\").exists():\n",
    "        assignment_root = candidate_root\n",
    "    else:\n",
    "        assignment_root = _find_assignment_root()\n",
    "else:\n",
    "    assignment_root = _find_assignment_root()\n",
    "\n",
    "print(f\"Using assignment_root: {assignment_root}\")\n",
    "\n",
    "# Source data folders (Part 1/2 artifacts)\n",
    "if \"output_path_step2\" not in locals() or not output_path_step2:\n",
    "    output_path_step2 = str(assignment_root / \"outputs_step2\")\n",
    "if \"output_dir\" not in locals() or not output_dir:\n",
    "    output_dir = str(assignment_root / \"outputs\")\n",
    "if \"Stock_Index_price_file\" not in locals() or not Stock_Index_price_file:\n",
    "    Stock_Index_price_file = str(assignment_root / \"nasdaq_stock.csv\")\n",
    "\n",
    "source_step2_dir = Path(output_path_step2)\n",
    "if not (source_step2_dir / \"stock_selected.csv\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Cannot find stock_selected.csv under {source_step2_dir}. \"\n",
    "        \"Please make sure Part 2 output exists.\"\n",
    "    )\n",
    "\n",
    "final_ratios_file = Path(output_dir) / \"final_ratios.csv\"\n",
    "if not final_ratios_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Cannot find final_ratios.csv under {Path(output_dir)}. \"\n",
    "        \"Please make sure Part 1 output exists.\"\n",
    "    )\n",
    "\n",
    "# New output root (sibling of outputs_step2)\n",
    "backtest_output_root = assignment_root / \"backtest_result\"\n",
    "backtest_output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Import reusable framework\n",
    "if str(assignment_root) not in sys.path:\n",
    "    sys.path.insert(0, str(assignment_root))\n",
    "\n",
    "from strategy_framework.backtest_engine import BacktestConfig\n",
    "from strategy_framework.runner import DataPaths, run_strategy_pipeline\n",
    "import importlib\n",
    "import strategy_framework.strategies.factory as strategy_factory\n",
    "importlib.reload(strategy_factory)\n",
    "from strategy_framework.strategies.factory import create_strategy, list_available_strategies\n",
    "\n",
    "# Enforce anti-lookahead defaults in notebook wrapper.\n",
    "# Notebook globals persist across runs, so stale values are clamped here.\n",
    "RETURN_MODE = str(locals().get(\"RETURN_MODE\", \"close_to_close\")).strip().lower()\n",
    "WEIGHT_LAG_DAYS = max(0, int(locals().get(\"WEIGHT_LAG_DAYS\", 0)))\n",
    "EXPOSURE_SIGNAL_LAG_DAYS = max(0, int(locals().get(\"EXPOSURE_SIGNAL_LAG_DAYS\", 0)))\n",
    "VOL_SCALE_LAG_DAYS = max(0, int(locals().get(\"VOL_SCALE_LAG_DAYS\", 0)))\n",
    "print(\n",
    "    f\"Backtest settings -> RETURN_MODE={RETURN_MODE}, \"\n",
    "    f\"WEIGHT_LAG_DAYS={WEIGHT_LAG_DAYS}, \"\n",
    "    f\"EXPOSURE_SIGNAL_LAG_DAYS={EXPOSURE_SIGNAL_LAG_DAYS}, \"\n",
    "    f\"VOL_SCALE_LAG_DAYS={VOL_SCALE_LAG_DAYS}\"\n",
    ")\n",
    "print(\"Anti-lookahead guardrail: lag settings are clamped to >= 0 day (set explicitly to avoid accidental double-lag).\")\n",
    "\n",
    "raw_force_config_name = locals().get(\"FORCE_CONFIG_NAME\", None)\n",
    "if raw_force_config_name is None:\n",
    "    FORCE_CONFIG_NAME = None\n",
    "else:\n",
    "    force_candidate = str(raw_force_config_name).strip()\n",
    "    FORCE_CONFIG_NAME = force_candidate if force_candidate and force_candidate.lower() not in {\"none\", \"null\", \"nan\"} else None\n",
    "\n",
    "strategy_options = list_available_strategies()\n",
    "if not strategy_options:\n",
    "    raise RuntimeError(\"No strategies are registered in strategy_framework.\")\n",
    "\n",
    "print(\"Please choose a strategy by number:\")\n",
    "for idx, name in enumerate(strategy_options, start=1):\n",
    "    print(f\"  {idx}. {name}\")\n",
    "\n",
    "default_choice = 1\n",
    "raw_default_choice = str(locals().get(\"STRATEGY_SELECTION_DEFAULT\", default_choice)).strip()\n",
    "if raw_default_choice.isdigit():\n",
    "    candidate_default = int(raw_default_choice)\n",
    "    if 1 <= candidate_default <= len(strategy_options):\n",
    "        default_choice = candidate_default\n",
    "\n",
    "try:\n",
    "    choice_text = input(f\"Enter strategy number [1-{len(strategy_options)}], default {default_choice}: \" ).strip()\n",
    "except Exception:\n",
    "    choice_text = \"\"\n",
    "\n",
    "if not choice_text:\n",
    "    choice_idx = default_choice\n",
    "else:\n",
    "    if not choice_text.isdigit():\n",
    "        raise ValueError(f\"Invalid strategy selection: {choice_text!r}. Please enter an integer from 1 to {len(strategy_options)}.\")\n",
    "    choice_idx = int(choice_text)\n",
    "    if not (1 <= choice_idx <= len(strategy_options)):\n",
    "        raise ValueError(f\"Strategy number out of range: {choice_idx}. Valid range: 1..{len(strategy_options)}.\")\n",
    "\n",
    "STRATEGY_NAME = strategy_options[choice_idx - 1]\n",
    "print(f\"Selected strategy #{choice_idx}: {STRATEGY_NAME}\")\n",
    "\n",
    "default_strategy_configs = {name: {} for name in strategy_options}\n",
    "STRATEGY_CONFIG = locals().get(\"STRATEGY_CONFIG\", default_strategy_configs.get(STRATEGY_NAME, {}))\n",
    "if STRATEGY_CONFIG is None:\n",
    "    STRATEGY_CONFIG = {}\n",
    "if not isinstance(STRATEGY_CONFIG, dict):\n",
    "    raise TypeError(\"STRATEGY_CONFIG must be a dict, e.g. {'top_n': 25}\")\n",
    "\n",
    "paths = DataPaths(\n",
    "    stock_selected_csv=str(source_step2_dir / \"stock_selected.csv\"),\n",
    "    final_ratios_csv=str(final_ratios_file),\n",
    "    stock_price_csv=str(Stock_Index_price_file),\n",
    "    output_step2_dir=str(backtest_output_root),\n",
    ")\n",
    "\n",
    "strategy_obj = create_strategy(\n",
    "    strategy_name=STRATEGY_NAME,\n",
    "    config=STRATEGY_CONFIG,\n",
    "    force_config_name=FORCE_CONFIG_NAME,\n",
    ")\n",
    "\n",
    "TARGET_ANNUAL_VOL = float(locals().get(\"TARGET_ANNUAL_VOL\", 0.20))\n",
    "MIN_EXPOSURE = float(locals().get(\"MIN_EXPOSURE\", 0.15))\n",
    "MAX_VOL_SCALE = float(locals().get(\"MAX_VOL_SCALE\", 1.00))\n",
    "MIN_VOL_SCALE = float(locals().get(\"MIN_VOL_SCALE\", 0.35))\n",
    "REGIME_BASE_EXPOSURE = locals().get(\"REGIME_BASE_EXPOSURE\", {0: 1.00, 1: 0.70, 2: 0.25})\n",
    "if not isinstance(REGIME_BASE_EXPOSURE, dict) or not {0, 1, 2}.issubset(set(REGIME_BASE_EXPOSURE.keys())):\n",
    "    raise ValueError(\"REGIME_BASE_EXPOSURE must be a dict containing keys {0,1,2}.\")\n",
    "\n",
    "print(\n",
    "    f\"Exposure config -> target_vol={TARGET_ANNUAL_VOL:.2f}, min_exposure={MIN_EXPOSURE:.2f}, \"\n",
    "    f\"max_vol_scale={MAX_VOL_SCALE:.2f}, min_vol_scale={MIN_VOL_SCALE:.2f}, \"\n",
    "    f\"regime_base_exposure={REGIME_BASE_EXPOSURE}\"\n",
    ")\n",
    "\n",
    "bt_cfg = BacktestConfig(\n",
    "    return_mode=RETURN_MODE,\n",
    "    weight_lag_days=WEIGHT_LAG_DAYS,\n",
    "    exposure_signal_lag_days=EXPOSURE_SIGNAL_LAG_DAYS,\n",
    "    vol_scale_lag_days=VOL_SCALE_LAG_DAYS,\n",
    "    target_annual_vol=TARGET_ANNUAL_VOL,\n",
    "    min_exposure=MIN_EXPOSURE,\n",
    "    max_vol_scale=MAX_VOL_SCALE,\n",
    "    min_vol_scale=MIN_VOL_SCALE,\n",
    "    regime_base_exposure=REGIME_BASE_EXPOSURE,\n",
    ")\n",
    "\n",
    "strategy_output_dir, strategy_signals, result = run_strategy_pipeline(\n",
    "    strategy=strategy_obj,\n",
    "    data_paths=paths,\n",
    "    backtest_config=bt_cfg,\n",
    "    force_config_name=FORCE_CONFIG_NAME,\n",
    ")\n",
    "\n",
    "strategy_output_dir = str(strategy_output_dir)\n",
    "CONFIG_NAME = Path(strategy_output_dir).name\n",
    "portfolio_weights_df = strategy_signals.weights_signal_df.copy()\n",
    "regime_df = strategy_signals.regime_df.copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Strategy pipeline (framework wrapper) finished\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Strategy name: {STRATEGY_NAME}\")\n",
    "print(f\"Available strategies: {', '.join(strategy_options)}\")\n",
    "print(f\"Config name: {CONFIG_NAME}\")\n",
    "print(f\"Source stock_selected: {source_step2_dir / 'stock_selected.csv'}\")\n",
    "print(f\"Output root: {backtest_output_root}\")\n",
    "print(f\"Strategy output directory: {strategy_output_dir}\")\n",
    "print(f\"Weights shape: {portfolio_weights_df.shape}\")\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Final NAV: {result['nav'].iloc[-1]:.4f}\")\n",
    "print(\"Run Cell 26 to generate/update strategy_dashboard.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Backtest Summary (already computed by framework in Cell 24) ============\n",
    "if \"strategy_output_dir\" not in locals() or \"CONFIG_NAME\" not in locals():\n",
    "    raise RuntimeError(\"Please run Cell 24 first to generate strategy_output_dir and CONFIG_NAME.\")\n",
    "\n",
    "result_file = os.path.join(strategy_output_dir, \"strategy_result.csv\")\n",
    "weights_file = os.path.join(strategy_output_dir, \"portfolio_weights.csv\")\n",
    "regime_file = os.path.join(strategy_output_dir, \"regime_state.csv\")\n",
    "\n",
    "if \"result\" not in locals() or result is None:\n",
    "    result = pd.read_csv(result_file, index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"Result file: {result_file}\")\n",
    "print(f\"Weights file: {weights_file}\")\n",
    "print(f\"Regime file: {regime_file}\")\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Date range: {result.index.min()} to {result.index.max()}\")\n",
    "print(f\"Final NAV: {result['nav'].iloc[-1]:.4f}\")\n",
    "print(\"Backtest settings in result:\")\n",
    "for c in [\"return_mode\", \"weight_lag_days\", \"exposure_signal_lag_days\", \"vol_scale_lag_days\"]:\n",
    "    if c in result.columns:\n",
    "        print(f\"  {c}: {result[c].iloc[-1]}\")\n",
    "print(f\"Mean turnover: {result['turnover'].iloc[1:].mean():.4f}\")\n",
    "print(f\"Annualized turnover: {(result['turnover'].iloc[1:].mean() * 252):.2f}\")\n",
    "print(f\"Average exposure: {result['exposure'].iloc[1:].mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Visualization (Thin Wrapper -> strategy_framework) ============\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if \"strategy_output_dir\" not in locals() or \"CONFIG_NAME\" not in locals():\n",
    "    raise RuntimeError(\"Please run Cell 24 first to generate strategy output.\")\n",
    "\n",
    "result_file = os.path.join(strategy_output_dir, \"strategy_result.csv\")\n",
    "result = pd.read_csv(result_file, index_col=0, parse_dates=True)\n",
    "print(f\"Loaded result from: {result_file}\")\n",
    "\n",
    "import importlib\n",
    "import strategy_framework.visualization as viz_mod\n",
    "viz_mod = importlib.reload(viz_mod)\n",
    "\n",
    "# Use strategy-scoped benchmark fallback cache to avoid cross-run stale-cache contamination.\n",
    "benchmark_fallback_dir = str(strategy_output_dir)\n",
    "\n",
    "comparison_df, stats_table, fig_file = viz_mod.build_strategy_dashboard(\n",
    "    result=result,\n",
    "    strategy_output_dir=strategy_output_dir,\n",
    "    output_path_step2=benchmark_fallback_dir,\n",
    "    config_name=CONFIG_NAME,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from strategy_framework.diagnostics import print_diagnostics_report, run_diagnostics\n",
    "\n",
    "if \"strategy_output_dir\" not in locals() or not strategy_output_dir:\n",
    "    raise RuntimeError(\"Please run Cell 24 first to generate strategy_output_dir.\")\n",
    "\n",
    "stock_price_csv = locals().get(\"Stock_Index_price_file\", None)\n",
    "stock_selected_csv = None\n",
    "if \"output_path_step2\" in locals() and output_path_step2:\n",
    "    stock_selected_csv = str(Path(output_path_step2) / \"stock_selected.csv\")\n",
    "\n",
    "diag = run_diagnostics(\n",
    "    strategy_output_dir=str(strategy_output_dir),\n",
    "    stock_price_csv=stock_price_csv,\n",
    "    stock_selected_csv=stock_selected_csv,\n",
    "    output_path_step2=locals().get(\"output_path_step2\", None),\n",
    "    mc_runs=int(locals().get(\"MC_RUNS\", 100)),\n",
    "    oos_split_date=str(locals().get(\"OOS_SPLIT_DATE\", \"2023-01-01\")),\n",
    "    save_artifacts=True,\n",
    ")\n",
    "\n",
    "print_diagnostics_report(diag)\n",
    "print(f\"Diagnostics artifacts saved under: {Path(strategy_output_dir) / 'diagnostics'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}