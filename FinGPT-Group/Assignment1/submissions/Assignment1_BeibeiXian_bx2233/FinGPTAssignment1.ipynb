{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi #1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff4xoVQoE2Ws",
        "outputId": "29c0f049-1173-4d1e-f928-f37f1d9b25a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 21 03:50:29 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   33C    P0             54W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "!pip -q uninstall -y sentence-transformers fastai cudf-cu12 pylibcudf-cu12 rapids-dask-dependency rapids-logger || true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh4z5Z8YGVf1",
        "outputId": "06a097b2-4660-4a66-894d-8c10d19f8dfb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping sentence-transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping fastai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pylibcudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping rapids-dask-dependency as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping rapids-logger as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "try:\n",
        "    wandb.finish()\n",
        "except Exception as e:\n",
        "    print(\"wandb.finish() skipped:\", e)"
      ],
      "metadata": {
        "id": "f-13mJeyf2Xp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "!pip -q install -U \"transformers>=4.45,<5\" \"huggingface-hub>=0.23\" \"tokenizers>=0.20\" \\\n",
        "  accelerate datasets peft bitsandbytes sentencepiece wandb rouge-score\n",
        "!pip -q install -U deepspeed"
      ],
      "metadata": {
        "id": "0C3RplQDGcYE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#QCHECK\n",
        "import torch, transformers, huggingface_hub, bitsandbytes\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda:\", torch.cuda.is_available(), torch.cuda.get_device_name(0))\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"hub:\", huggingface_hub.__version__)\n",
        "print(\"bnb:\", bitsandbytes.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbMRh3upGi_N",
        "outputId": "2a3c09a9-7093-4c12-caf7-77cfa04848b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.6.0+cu124\n",
            "cuda: True NVIDIA A100-SXM4-80GB\n",
            "transformers: 4.57.6\n",
            "hub: 0.36.2\n",
            "bnb: 0.49.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "%cd /content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code\n",
        "!mkdir -p finetuned_models\n",
        "!ls -lah"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EZRQe4VGz7B",
        "outputId": "172d9349-12a4-4f8f-a74c-49eba3471255"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code\n",
            "total 84K\n",
            "drwxr-xr-x 3 root root 4.0K Feb 21 03:51 .\n",
            "drwxr-xr-x 5 root root 4.0K Feb 21 03:47 ..\n",
            "-rw-r--r-- 1 root root  783 Feb 21 03:47 config.json\n",
            "drwxr-xr-x 2 root root 4.0K Feb 21 03:51 finetuned_models\n",
            "-rw-r--r-- 1 root root  42K Feb 21 03:47 FinGPT-Assignment1.ipynb\n",
            "-rw-r--r-- 1 root root 8.7K Feb 21 03:47 train_lora.py\n",
            "-rw-r--r-- 1 root root  668 Feb 21 03:47 train.sh\n",
            "-rw-r--r-- 1 root root 5.6K Feb 21 03:47 utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-wKRUUmIP_bC"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "import os #refreshed keys\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"\"\n",
        "os.environ[\"FINNHUB_KEY\"] = \"\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "from huggingface_hub import login\n",
        "login(token=os.environ[\"HF_TOKEN\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fz11fXtGYVj",
        "outputId": "dfed2491-85eb-41fb-ee43-d86530f434d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "!git clone https://github.com/AI4Finance-Foundation/STAT-GR5398-Spring-2026.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBd0k9MnHSJo",
        "outputId": "a172efc0-b314-4441-d7d7-1d3206583f9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'STAT-GR5398-Spring-2026'...\n",
            "remote: Enumerating objects: 1100, done.\u001b[K\n",
            "remote: Counting objects: 100% (797/797), done.\u001b[K\n",
            "remote: Compressing objects: 100% (689/689), done.\u001b[K\n",
            "remote: Total 1100 (delta 244), reused 436 (delta 102), pack-reused 303 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1100/1100), 80.54 MiB | 16.12 MiB/s, done.\n",
            "Resolving deltas: 100% (307/307), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "!pip -q uninstall -y opencv-python-headless opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to0Z0SlEf4Hw",
        "outputId": "f997fd7e-717f-411f-cc8a-a80f5c7869f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "%cd /content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1\n",
        "!find . -maxdepth 4 -type d | egrep \"dow|dji|fingpt|dataset|train|test\" | head -n 120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo-fOIl3KvdG",
        "outputId": "be95c9f7-449f-44f6-db34-bdc14ae267bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "!pip install --upgrade wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hEa1h2Fw-B-",
        "outputId": "c75cf91e-fdfa-490b-c1cd-ef4a10b2f599"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11\n",
        "import wandb\n",
        "\n",
        "run = wandb.init(project=\"test-login-check\")\n",
        "print(\"Logged in as:\", wandb.run.entity)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "EdG_89e6p77Z",
        "outputId": "30978bb3-9c15-4310-d52c-41734b7a8295"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create a new API key at: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Store your API key securely and do not share it.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste your API key and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Invalid API key: API key may only contain the letters A-Z, digits and underscores.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 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\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Invalid choice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create a new API key at: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Store your API key securely and do not share it.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste your API key and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbx2233\u001b[0m (\u001b[33mbx2233-columbia-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/wandb/run-20260221_035221-rspolzqw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bx2233-columbia-university/test-login-check/runs/rspolzqw' target=\"_blank\">clear-valley-13</a></strong> to <a href='https://wandb.ai/bx2233-columbia-university/test-login-check' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bx2233-columbia-university/test-login-check' target=\"_blank\">https://wandb.ai/bx2233-columbia-university/test-login-check</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bx2233-columbia-university/test-login-check/runs/rspolzqw' target=\"_blank\">https://wandb.ai/bx2233-columbia-university/test-login-check/runs/rspolzqw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as: bx2233-columbia-university\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clear-valley-13</strong> at: <a href='https://wandb.ai/bx2233-columbia-university/test-login-check/runs/rspolzqw' target=\"_blank\">https://wandb.ai/bx2233-columbia-university/test-login-check/runs/rspolzqw</a><br> View project at: <a href='https://wandb.ai/bx2233-columbia-university/test-login-check' target=\"_blank\">https://wandb.ai/bx2233-columbia-university/test-login-check</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260221_035221-rspolzqw/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RE NEWRUN\n",
        "import wandb\n",
        "wandb.init(\n",
        "    project=\"fingpt-forecaster\",\n",
        "    name=\"dow30_lora_v1_reconnect\",\n",
        "    reinit=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "nV_es9ehgIbk",
        "outputId": "6ba81635-e588-4239-b3a9-f70818ada626"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260221_001715-7hqmoyr2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bx2233-columbia-university/fingpt-forecaster/runs/7hqmoyr2' target=\"_blank\">dow30_lora_v1_reconnect</a></strong> to <a href='https://wandb.ai/bx2233-columbia-university/fingpt-forecaster' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bx2233-columbia-university/fingpt-forecaster' target=\"_blank\">https://wandb.ai/bx2233-columbia-university/fingpt-forecaster</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bx2233-columbia-university/fingpt-forecaster/runs/7hqmoyr2' target=\"_blank\">https://wandb.ai/bx2233-columbia-university/fingpt-forecaster/runs/7hqmoyr2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bx2233-columbia-university/fingpt-forecaster/runs/7hqmoyr2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7afc488bfe90>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "xyKPCZpehc6d"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#QCHECK\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxjRNEYMcuFc",
        "outputId": "d6d8f1e5-8587-4557-9eda-1746f2863469"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.6.0+cu124\n",
            "cuda: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12\n",
        "import os, sys, importlib.util\n",
        "print(\"cwd:\", os.getcwd())\n",
        "print(\"first sys.path:\", sys.path[0])\n",
        "\n",
        "spec = importlib.util.find_spec(\"torchvision\")\n",
        "print(\"torchvision spec:\", spec)\n",
        "print(\"torchvision origin:\", spec.origin if spec else None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZqZVlBhJhi1",
        "outputId": "42d3573f-a27c-4eec-aff2-29627403f667"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cwd: /content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1\n",
            "first sys.path: /content\n",
            "torchvision spec: ModuleSpec(name='torchvision', loader=<_frozen_importlib_external.SourceFileLoader object at 0x78815c592510>, origin='/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py', submodule_search_locations=['/usr/local/lib/python3.11/dist-packages/torchvision'])\n",
            "torchvision origin: /usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CHECK\n",
        "!ls -lah | egrep -i \"torchvision\"\n",
        "!find . -maxdepth 2 -iname \"torchvision*\" -print"
      ],
      "metadata": {
        "id": "154prBBmKEG0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHECK\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QBXK4SJK7Ix",
        "outputId": "1a473403-c299-4bb1-ca7b-d12c57b39f74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13\n",
        "!pip -q uninstall -y torch torchvision torchaudio\n",
        "!pip -q install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Arl2uVj0K_IN",
        "outputId": "8d8a89d9-45ae-4f62-d457-d5797d2f29ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.5/768.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14 RESTART SESSION BEFORE\n",
        "import torch, torchvision\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torchvision:\", torchvision.__version__)\n",
        "import torchvision.ops\n",
        "print(\"torchvision ops OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2vdDmZuKQkP",
        "outputId": "feb00734-56f4-42b9-b4ea-6db10f404795"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.6.0+cu124\n",
            "torchvision: 0.21.0+cu124\n",
            "torchvision ops OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15\n",
        "%cd /content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code\n",
        "\n",
        "!grep -n \"prepare_model_for_int8_training\" -n train_lora.py\n",
        "!sed -i 's/prepare_model_for_int8_training/prepare_model_for_kbit_training/g' train_lora.py\n",
        "\n",
        "!grep -n \"prepare_model_for_\" -n train_lora.py | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCm_x87mh_ZP",
        "outputId": "816909d9-e71c-4dc2-80c4-8d8f41d9a5b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code\n",
            "25:    prepare_model_for_int8_training,\n",
            "174:    model = prepare_model_for_int8_training(model)\n",
            "25:    prepare_model_for_kbit_training,\n",
            "174:    model = prepare_model_for_kbit_training(model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CLEANUP\n",
        "%cd /content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code\n",
        "\n",
        "!sed -i 's/prepare_model_for_int8_training/prepare_model_for_kbit_training/g' train_lora.py\n",
        "\n",
        "!grep -n \"prepare_model_for_int8_training\" train_lora.py || echo \"✅ old name gone\"\n",
        "!grep -n \"prepare_model_for_kbit_training\" train_lora.py | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvERoQnANINN",
        "outputId": "5d4ab901-c702-4dfe-9ef1-9b8d4cbb6b49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code\n",
            "✅ old name gone\n",
            "25:    prepare_model_for_kbit_training,\n",
            "174:    model = prepare_model_for_kbit_training(model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#16\n",
        "!python train_lora.py --help | head -n 40"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4K5Yw3zNgR3",
        "outputId": "25e08081-56ed-4c34-c0b3-2250b751415f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-21 03:54:16.364580: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-02-21 03:54:16.382424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771646056.404043    4568 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771646056.410426    4568 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2026-02-21 03:54:16.431768: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: train_lora.py [-h] [--local_rank LOCAL_RANK] [--run_name RUN_NAME]\n",
            "                     --dataset DATASET [--test_dataset TEST_DATASET]\n",
            "                     --base_model {chatglm2,llama2} [--max_length MAX_LENGTH]\n",
            "                     [--batch_size BATCH_SIZE] [--learning_rate LEARNING_RATE]\n",
            "                     [--weight_decay WEIGHT_DECAY] [--num_epochs NUM_EPOCHS]\n",
            "                     [--num_workers NUM_WORKERS] [--log_interval LOG_INTERVAL]\n",
            "                     [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                     [--warmup_ratio WARMUP_RATIO] [--ds_config DS_CONFIG]\n",
            "                     [--scheduler SCHEDULER]\n",
            "                     [--instruct_template INSTRUCT_TEMPLATE]\n",
            "                     [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "                     [--eval_steps EVAL_STEPS] [--from_remote FROM_REMOTE]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --local_rank LOCAL_RANK\n",
            "  --run_name RUN_NAME\n",
            "  --dataset DATASET\n",
            "  --test_dataset TEST_DATASET\n",
            "  --base_model {chatglm2,llama2}\n",
            "  --max_length MAX_LENGTH\n",
            "  --batch_size BATCH_SIZE\n",
            "                        The train batch size per device\n",
            "  --learning_rate LEARNING_RATE\n",
            "                        The learning rate\n",
            "  --weight_decay WEIGHT_DECAY\n",
            "                        weight decay\n",
            "  --num_epochs NUM_EPOCHS\n",
            "                        The training epochs\n",
            "  --num_workers NUM_WORKERS\n",
            "                        dataloader workers\n",
            "  --log_interval LOG_INTERVAL\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n",
            "  --warmup_ratio WARMUP_RATIO\n",
            "  --ds_config DS_CONFIG\n",
            "  --scheduler SCHEDULER\n",
            "  --instruct_template INSTRUCT_TEMPLATE\n",
            "  --evaluation_strategy EVALUATION_STRATEGY\n",
            "  --eval_steps EVAL_STEPS\n",
            "  --from_remote FROM_REMOTE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt-get update -qq\n",
        "apt-get install -y -qq libopenmpi-dev openmpi-bin\n",
        "pip -q install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1q210QbaN4_X",
        "outputId": "964e1dce-492f-4aa3-d2ef-03f9cd7f84cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 49.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content\n",
        "!ls -lah /content/STAT-GR5398-Spring-2026/FinGPT-Group/\n",
        "!find /content -maxdepth 5 -name \"train_lora.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fYF9JKx7h00b",
        "outputId": "b076075d-9cec-422a-c8dd-ab329a91966e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28K\n",
            "drwxr-xr-x 1 root root 4.0K Feb 21 00:16 .\n",
            "drwxr-xr-x 1 root root 4.0K Feb 20 23:55 ..\n",
            "drwxr-xr-x 1 root root 4.0K Jul 15  2025 .config\n",
            "drwxr-xr-x 2 root root 4.0K Feb 21 00:09 finetuned_models\n",
            "drwxr-xr-x 1 root root 4.0K Jul 15  2025 sample_data\n",
            "drwxr-xr-x 6 root root 4.0K Feb 21 00:16 STAT-GR5398-Spring-2026\n",
            "drwxr-xr-x 7 root root 4.0K Feb 21 00:17 wandb\n",
            "total 16K\n",
            "drwxr-xr-x 3 root root 4.0K Feb 21 00:16 .\n",
            "drwxr-xr-x 6 root root 4.0K Feb 21 00:16 ..\n",
            "drwxr-xr-x 5 root root 4.0K Feb 21 00:16 Assignment1\n",
            "-rw-r--r-- 1 root root   25 Feb 21 00:16 README.md\n",
            "/content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code/train_lora.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code\n",
        "export DS_ACCELERATOR=cuda\n",
        "\n",
        "python train_lora.py \\\n",
        "  --run_name dow30_lora_v1 \\\n",
        "  --base_model llama2 \\\n",
        "  --dataset fingpt-forecaster-dow30-20231231-20241231-1-4-06 \\\n",
        "  --max_length 4096 \\\n",
        "  --batch_size 1 \\\n",
        "  --gradient_accumulation_steps 16 \\\n",
        "  --learning_rate 5e-5 \\\n",
        "  --num_epochs 1 \\\n",
        "  --log_interval 10 \\\n",
        "  --warmup_ratio 0.03 \\\n",
        "  --scheduler constant \\\n",
        "  --evaluation_strategy steps \\\n",
        "  --eval_steps 50 \\\n",
        "  --ds_config config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PROwMRfOSEI7",
        "outputId": "1ae8d69a-a8c0-4f23-9f45-0bc99fa766a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLUActivation()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            ")\n",
            "original dataset length:  1230\n",
            "filtered dataset length:  1230\n",
            "Cupy Buffers Initialized Successfully.\n",
            "Pop out errors\n",
            "Finished the initialization step at rank 0\n",
            "[2026-02-21 00:23:24,321] [WARNING] [lr_schedules.py:690:get_lr] Attempting to get learning rate from scheduler before it has started\n",
            "{'loss': 11.3557, 'grad_norm': 0.0019495344196451391, 'learning_rate': 5e-05, 'epoch': 0.13}\n",
            "{'loss': 1.8994, 'grad_norm': 0.0003704562888702429, 'learning_rate': 5e-05, 'epoch': 0.26}\n",
            "{'loss': 1.2269, 'grad_norm': 7.439861633682821e-05, 'learning_rate': 5e-05, 'epoch': 0.39}\n",
            "{'loss': 0.848, 'grad_norm': 0.00011325332278179394, 'learning_rate': 5e-05, 'epoch': 0.52}\n",
            "{'loss': 0.782, 'grad_norm': 4.2887513245541686e-05, 'learning_rate': 5e-05, 'epoch': 0.65}\n",
            "{'eval_loss': 0.7109150290489197, 'eval_runtime': 103.5306, 'eval_samples_per_second': 2.898, 'eval_steps_per_second': 2.898, 'epoch': 0.65}\n",
            "{'loss': 0.6964, 'grad_norm': 5.04324159530414e-05, 'learning_rate': 5e-05, 'epoch': 0.78}\n",
            "{'loss': 0.6012, 'grad_norm': 3.054725687653274e-05, 'learning_rate': 5e-05, 'epoch': 0.91}\n",
            "{'train_runtime': 1429.0045, 'train_samples_per_second': 0.861, 'train_steps_per_second': 0.054, 'train_loss': 2.3142723913316603, 'epoch': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-02-21 00:22:34.466775: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-02-21 00:22:34.484789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771633354.506932    9322 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771633354.513340    9322 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2026-02-21 00:22:34.535145: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "wandb: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
            "wandb: Currently logged in as: bx2233 (bx2233-columbia-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "\rLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\rLoading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.43s/it]\rLoading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.21s/it]\rLoading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.39s/it]\n",
            "\rMap:   0%|          | 0/300 [00:00<?, ? examples/s]\rMap:   8%|▊         | 24/300 [00:00<00:01, 232.52 examples/s]\rMap:  16%|█▌        | 48/300 [00:00<00:01, 227.70 examples/s]\rMap:  27%|██▋       | 80/300 [00:00<00:01, 214.05 examples/s]\rMap:  34%|███▍      | 102/300 [00:00<00:00, 211.84 examples/s]\rMap:  45%|████▌     | 135/300 [00:00<00:00, 211.83 examples/s]\rMap:  56%|█████▌    | 168/300 [00:00<00:00, 214.06 examples/s]\rMap:  63%|██████▎   | 190/300 [00:00<00:00, 213.73 examples/s]\rMap:  71%|███████   | 212/300 [00:00<00:00, 212.95 examples/s]\rMap:  79%|███████▉  | 238/300 [00:01<00:00, 221.26 examples/s]\rMap:  90%|█████████ | 270/300 [00:01<00:00, 214.56 examples/s]\rMap:  98%|█████████▊| 293/300 [00:01<00:00, 214.54 examples/s]\rMap: 100%|██████████| 300/300 [00:01<00:00, 190.75 examples/s]\n",
            "\rFilter:   0%|          | 0/300 [00:00<?, ? examples/s]\rFilter: 100%|██████████| 300/300 [00:00<00:00, 585.25 examples/s]\rFilter: 100%|██████████| 300/300 [00:00<00:00, 583.09 examples/s]\n",
            "/content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code/train_lora.py:189: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.\n",
            "WARNING:accelerate.accelerator:Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 16. Using DeepSpeed's value.\n",
            "wandb: setting up run k1voplev\n",
            "wandb: Tracking run with wandb version 0.25.0\n",
            "wandb: Run data is saved locally in /content/STAT-GR5398-Spring-2026/FinGPT-Group/Assignment1/source_code/wandb/run-20260221_002324-k1voplev\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run dow30_lora_v1\n",
            "wandb: ⭐️ View project at https://wandb.ai/bx2233-columbia-university/fingpt-forecaster\n",
            "wandb: 🚀 View run at https://wandb.ai/bx2233-columbia-university/fingpt-forecaster/runs/k1voplev\n",
            "\r  0%|          | 0/77 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/deepspeed/runtime/fp16/onebit/zoadam.py:213: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1661.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "\r  1%|▏         | 1/77 [00:20<26:28, 20.90s/it]\r  3%|▎         | 2/77 [00:37<23:09, 18.52s/it]\r  4%|▍         | 3/77 [00:54<21:47, 17.66s/it]\r  5%|▌         | 4/77 [01:11<21:08, 17.38s/it]\r  6%|▋         | 5/77 [01:28<20:37, 17.19s/it]\r  8%|▊         | 6/77 [01:44<20:01, 16.92s/it]\r  9%|▉         | 7/77 [02:00<19:25, 16.66s/it]\r 10%|█         | 8/77 [02:16<18:44, 16.29s/it]\r 12%|█▏        | 9/77 [02:33<18:41, 16.49s/it]\r 13%|█▎        | 10/77 [02:49<18:19, 16.41s/it]\r                                               \r\r 13%|█▎        | 10/77 [02:49<18:19, 16.41s/it]\r 14%|█▍        | 11/77 [03:05<17:56, 16.32s/it]\r 16%|█▌        | 12/77 [03:21<17:41, 16.34s/it]\r 17%|█▋        | 13/77 [03:38<17:32, 16.45s/it]\r 18%|█▊        | 14/77 [03:55<17:18, 16.48s/it]\r 19%|█▉        | 15/77 [04:11<17:05, 16.54s/it]\r 21%|██        | 16/77 [04:28<16:53, 16.62s/it]\r 22%|██▏       | 17/77 [04:45<16:40, 16.67s/it]\r 23%|██▎       | 18/77 [05:01<16:15, 16.53s/it]\r 25%|██▍       | 19/77 [05:18<15:57, 16.51s/it]\r 26%|██▌       | 20/77 [05:34<15:45, 16.59s/it]\r                                               \r\r 26%|██▌       | 20/77 [05:34<15:45, 16.59s/it]\r 27%|██▋       | 21/77 [05:51<15:30, 16.61s/it]\r 29%|██▊       | 22/77 [06:07<15:10, 16.55s/it]\r 30%|██▉       | 23/77 [06:24<14:59, 16.66s/it]\r 31%|███       | 24/77 [06:41<14:44, 16.69s/it]\r 32%|███▏      | 25/77 [06:58<14:25, 16.64s/it]\r 34%|███▍      | 26/77 [07:14<14:03, 16.53s/it]\r 35%|███▌      | 27/77 [07:30<13:42, 16.44s/it]\r 36%|███▋      | 28/77 [07:47<13:26, 16.47s/it]\r 38%|███▊      | 29/77 [08:03<13:12, 16.51s/it]\r 39%|███▉      | 30/77 [08:19<12:48, 16.36s/it]\r                                               \r\r 39%|███▉      | 30/77 [08:19<12:48, 16.36s/it]\r 40%|████      | 31/77 [08:36<12:39, 16.51s/it]\r 42%|████▏     | 32/77 [08:53<12:21, 16.49s/it]\r 43%|████▎     | 33/77 [09:10<12:12, 16.64s/it]\r 44%|████▍     | 34/77 [09:26<11:58, 16.71s/it]\r 45%|████▌     | 35/77 [09:43<11:44, 16.77s/it]\r 47%|████▋     | 36/77 [10:00<11:28, 16.80s/it]\r 48%|████▊     | 37/77 [10:16<11:04, 16.60s/it]\r 49%|████▉     | 38/77 [10:33<10:50, 16.67s/it]\r 51%|█████     | 39/77 [10:50<10:29, 16.57s/it]\r 52%|█████▏    | 40/77 [11:06<10:12, 16.55s/it]\r                                               \r\r 52%|█████▏    | 40/77 [11:06<10:12, 16.55s/it]\r 53%|█████▎    | 41/77 [11:23<10:03, 16.76s/it]\r 55%|█████▍    | 42/77 [11:40<09:48, 16.81s/it]\r 56%|█████▌    | 43/77 [11:57<09:35, 16.92s/it]\r 57%|█████▋    | 44/77 [12:14<09:12, 16.74s/it]\r 58%|█████▊    | 45/77 [12:30<08:54, 16.70s/it]\r 60%|█████▉    | 46/77 [12:47<08:40, 16.78s/it]\r 61%|██████    | 47/77 [13:05<08:27, 16.93s/it]\r 62%|██████▏   | 48/77 [13:21<08:08, 16.85s/it]\r 64%|██████▎   | 49/77 [13:38<07:52, 16.87s/it]\r 65%|██████▍   | 50/77 [13:55<07:33, 16.81s/it]\r                                               \r\r 65%|██████▍   | 50/77 [13:55<07:33, 16.81s/it]\n",
            "\r  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\n",
            "\r  1%|          | 2/300 [00:00<00:51,  5.79it/s]\u001b[A\n",
            "\r  1%|          | 3/300 [00:00<01:09,  4.27it/s]\u001b[A\n",
            "\r  1%|▏         | 4/300 [00:01<01:23,  3.56it/s]\u001b[A\n",
            "\r  2%|▏         | 5/300 [00:01<01:27,  3.38it/s]\u001b[A\n",
            "\r  2%|▏         | 6/300 [00:01<01:28,  3.33it/s]\u001b[A\n",
            "\r  2%|▏         | 7/300 [00:01<01:30,  3.23it/s]\u001b[A\n",
            "\r  3%|▎         | 8/300 [00:02<01:34,  3.10it/s]\u001b[A\n",
            "\r  3%|▎         | 9/300 [00:02<01:33,  3.11it/s]\u001b[A\n",
            "\r  3%|▎         | 10/300 [00:02<01:32,  3.12it/s]\u001b[A\n",
            "\r  4%|▎         | 11/300 [00:03<01:32,  3.12it/s]\u001b[A\n",
            "\r  4%|▍         | 12/300 [00:03<01:34,  3.05it/s]\u001b[A\n",
            "\r  4%|▍         | 13/300 [00:03<01:33,  3.06it/s]\u001b[A\n",
            "\r  5%|▍         | 14/300 [00:04<01:37,  2.94it/s]\u001b[A\n",
            "\r  5%|▌         | 15/300 [00:04<01:35,  2.97it/s]\u001b[A\n",
            "\r  5%|▌         | 16/300 [00:04<01:34,  3.00it/s]\u001b[A\n",
            "\r  6%|▌         | 17/300 [00:05<01:34,  3.01it/s]\u001b[A\n",
            "\r  6%|▌         | 18/300 [00:05<01:34,  2.99it/s]\u001b[A\n",
            "\r  6%|▋         | 19/300 [00:06<01:35,  2.94it/s]\u001b[A\n",
            "\r  7%|▋         | 20/300 [00:06<01:35,  2.93it/s]\u001b[A\n",
            "\r  7%|▋         | 21/300 [00:06<01:38,  2.83it/s]\u001b[A\n",
            "\r  7%|▋         | 22/300 [00:07<01:36,  2.88it/s]\u001b[A\n",
            "\r  8%|▊         | 23/300 [00:07<01:36,  2.88it/s]\u001b[A\n",
            "\r  8%|▊         | 24/300 [00:07<01:35,  2.88it/s]\u001b[A\n",
            "\r  8%|▊         | 25/300 [00:08<01:33,  2.94it/s]\u001b[A\n",
            "\r  9%|▊         | 26/300 [00:08<01:38,  2.78it/s]\u001b[A\n",
            "\r  9%|▉         | 27/300 [00:08<01:39,  2.76it/s]\u001b[A\n",
            "\r  9%|▉         | 28/300 [00:09<01:38,  2.76it/s]\u001b[A\n",
            "\r 10%|▉         | 29/300 [00:09<01:39,  2.72it/s]\u001b[A\n",
            "\r 10%|█         | 30/300 [00:09<01:35,  2.83it/s]\u001b[A\n",
            "\r 10%|█         | 31/300 [00:10<01:31,  2.93it/s]\u001b[A\n",
            "\r 11%|█         | 32/300 [00:10<01:28,  3.02it/s]\u001b[A\n",
            "\r 11%|█         | 33/300 [00:10<01:26,  3.08it/s]\u001b[A\n",
            "\r 11%|█▏        | 34/300 [00:11<01:25,  3.10it/s]\u001b[A\n",
            "\r 12%|█▏        | 35/300 [00:11<01:24,  3.12it/s]\u001b[A\n",
            "\r 12%|█▏        | 36/300 [00:11<01:28,  2.97it/s]\u001b[A\n",
            "\r 12%|█▏        | 37/300 [00:12<01:31,  2.87it/s]\u001b[A\n",
            "\r 13%|█▎        | 38/300 [00:12<01:28,  2.95it/s]\u001b[A\n",
            "\r 13%|█▎        | 39/300 [00:12<01:26,  3.02it/s]\u001b[A\n",
            "\r 13%|█▎        | 40/300 [00:13<01:25,  3.02it/s]\u001b[A\n",
            "\r 14%|█▎        | 41/300 [00:13<01:26,  2.98it/s]\u001b[A\n",
            "\r 14%|█▍        | 42/300 [00:13<01:26,  2.98it/s]\u001b[A\n",
            "\r 14%|█▍        | 43/300 [00:14<01:27,  2.92it/s]\u001b[A\n",
            "\r 15%|█▍        | 44/300 [00:14<01:26,  2.97it/s]\u001b[A\n",
            "\r 15%|█▌        | 45/300 [00:14<01:28,  2.89it/s]\u001b[A\n",
            "\r 15%|█▌        | 46/300 [00:15<01:29,  2.84it/s]\u001b[A\n",
            "\r 16%|█▌        | 47/300 [00:15<01:28,  2.87it/s]\u001b[A\n",
            "\r 16%|█▌        | 48/300 [00:15<01:25,  2.94it/s]\u001b[A\n",
            "\r 16%|█▋        | 49/300 [00:16<01:27,  2.88it/s]\u001b[A\n",
            "\r 17%|█▋        | 50/300 [00:16<01:29,  2.79it/s]\u001b[A\n",
            "\r 17%|█▋        | 51/300 [00:17<01:27,  2.86it/s]\u001b[A\n",
            "\r 17%|█▋        | 52/300 [00:17<01:26,  2.87it/s]\u001b[A\n",
            "\r 18%|█▊        | 53/300 [00:17<01:26,  2.85it/s]\u001b[A\n",
            "\r 18%|█▊        | 54/300 [00:18<01:28,  2.78it/s]\u001b[A\n",
            "\r 18%|█▊        | 55/300 [00:18<01:30,  2.71it/s]\u001b[A\n",
            "\r 19%|█▊        | 56/300 [00:18<01:30,  2.69it/s]\u001b[A\n",
            "\r 19%|█▉        | 57/300 [00:19<01:26,  2.80it/s]\u001b[A\n",
            "\r 19%|█▉        | 58/300 [00:19<01:27,  2.78it/s]\u001b[A\n",
            "\r 20%|█▉        | 59/300 [00:19<01:24,  2.86it/s]\u001b[A\n",
            "\r 20%|██        | 60/300 [00:20<01:21,  2.95it/s]\u001b[A\n",
            "\r 20%|██        | 61/300 [00:20<01:22,  2.89it/s]\u001b[A\n",
            "\r 21%|██        | 62/300 [00:20<01:22,  2.90it/s]\u001b[A\n",
            "\r 21%|██        | 63/300 [00:21<01:20,  2.93it/s]\u001b[A\n",
            "\r 21%|██▏       | 64/300 [00:21<01:19,  2.96it/s]\u001b[A\n",
            "\r 22%|██▏       | 65/300 [00:21<01:21,  2.89it/s]\u001b[A\n",
            "\r 22%|██▏       | 66/300 [00:22<01:21,  2.88it/s]\u001b[A\n",
            "\r 22%|██▏       | 67/300 [00:22<01:22,  2.83it/s]\u001b[A\n",
            "\r 23%|██▎       | 68/300 [00:22<01:19,  2.92it/s]\u001b[A\n",
            "\r 23%|██▎       | 69/300 [00:23<01:20,  2.86it/s]\u001b[A\n",
            "\r 23%|██▎       | 70/300 [00:23<01:19,  2.89it/s]\u001b[A\n",
            "\r 24%|██▎       | 71/300 [00:24<01:20,  2.83it/s]\u001b[A\n",
            "\r 24%|██▍       | 72/300 [00:24<01:19,  2.87it/s]\u001b[A\n",
            "\r 24%|██▍       | 73/300 [00:24<01:18,  2.89it/s]\u001b[A\n",
            "\r 25%|██▍       | 74/300 [00:25<01:18,  2.89it/s]\u001b[A\n",
            "\r 25%|██▌       | 75/300 [00:25<01:19,  2.82it/s]\u001b[A\n",
            "\r 25%|██▌       | 76/300 [00:25<01:19,  2.83it/s]\u001b[A\n",
            "\r 26%|██▌       | 77/300 [00:26<01:21,  2.75it/s]\u001b[A\n",
            "\r 26%|██▌       | 78/300 [00:26<01:20,  2.76it/s]\u001b[A\n",
            "\r 26%|██▋       | 79/300 [00:26<01:18,  2.83it/s]\u001b[A\n",
            "\r 27%|██▋       | 80/300 [00:27<01:17,  2.83it/s]\u001b[A\n",
            "\r 27%|██▋       | 81/300 [00:27<01:16,  2.87it/s]\u001b[A\n",
            "\r 27%|██▋       | 82/300 [00:27<01:14,  2.94it/s]\u001b[A\n",
            "\r 28%|██▊       | 83/300 [00:28<01:14,  2.91it/s]\u001b[A\n",
            "\r 28%|██▊       | 84/300 [00:28<01:13,  2.92it/s]\u001b[A\n",
            "\r 28%|██▊       | 85/300 [00:28<01:13,  2.93it/s]\u001b[A\n",
            "\r 29%|██▊       | 86/300 [00:29<01:14,  2.86it/s]\u001b[A\n",
            "\r 29%|██▉       | 87/300 [00:29<01:13,  2.90it/s]\u001b[A\n",
            "\r 29%|██▉       | 88/300 [00:29<01:13,  2.90it/s]\u001b[A\n",
            "\r 30%|██▉       | 89/300 [00:30<01:14,  2.83it/s]\u001b[A\n",
            "\r 30%|███       | 90/300 [00:30<01:15,  2.78it/s]\u001b[A\n",
            "\r 30%|███       | 91/300 [00:31<01:15,  2.77it/s]\u001b[A\n",
            "\r 31%|███       | 92/300 [00:31<01:15,  2.76it/s]\u001b[A\n",
            "\r 31%|███       | 93/300 [00:31<01:12,  2.86it/s]\u001b[A\n",
            "\r 31%|███▏      | 94/300 [00:32<01:09,  2.95it/s]\u001b[A\n",
            "\r 32%|███▏      | 95/300 [00:32<01:09,  2.94it/s]\u001b[A\n",
            "\r 32%|███▏      | 96/300 [00:32<01:08,  2.97it/s]\u001b[A\n",
            "\r 32%|███▏      | 97/300 [00:33<01:10,  2.89it/s]\u001b[A\n",
            "\r 33%|███▎      | 98/300 [00:33<01:08,  2.93it/s]\u001b[A\n",
            "\r 33%|███▎      | 99/300 [00:33<01:07,  2.96it/s]\u001b[A\n",
            "\r 33%|███▎      | 100/300 [00:34<01:07,  2.98it/s]\u001b[A\n",
            "\r 34%|███▎      | 101/300 [00:34<01:08,  2.89it/s]\u001b[A\n",
            "\r 34%|███▍      | 102/300 [00:34<01:08,  2.91it/s]\u001b[A\n",
            "\r 34%|███▍      | 103/300 [00:35<01:06,  2.94it/s]\u001b[A\n",
            "\r 35%|███▍      | 104/300 [00:35<01:07,  2.92it/s]\u001b[A\n",
            "\r 35%|███▌      | 105/300 [00:35<01:05,  2.97it/s]\u001b[A\n",
            "\r 35%|███▌      | 106/300 [00:36<01:04,  3.00it/s]\u001b[A\n",
            "\r 36%|███▌      | 107/300 [00:36<01:08,  2.84it/s]\u001b[A\n",
            "\r 36%|███▌      | 108/300 [00:36<01:07,  2.83it/s]\u001b[A\n",
            "\r 36%|███▋      | 109/300 [00:37<01:05,  2.93it/s]\u001b[A\n",
            "\r 37%|███▋      | 110/300 [00:37<01:05,  2.90it/s]\u001b[A\n",
            "\r 37%|███▋      | 111/300 [00:37<01:07,  2.82it/s]\u001b[A\n",
            "\r 37%|███▋      | 112/300 [00:38<01:05,  2.89it/s]\u001b[A\n",
            "\r 38%|███▊      | 113/300 [00:38<01:04,  2.90it/s]\u001b[A\n",
            "\r 38%|███▊      | 114/300 [00:38<01:03,  2.91it/s]\u001b[A\n",
            "\r 38%|███▊      | 115/300 [00:39<01:04,  2.87it/s]\u001b[A\n",
            "\r 39%|███▊      | 116/300 [00:39<01:05,  2.79it/s]\u001b[A\n",
            "\r 39%|███▉      | 117/300 [00:40<01:06,  2.76it/s]\u001b[A\n",
            "\r 39%|███▉      | 118/300 [00:40<01:06,  2.72it/s]\u001b[A\n",
            "\r 40%|███▉      | 119/300 [00:40<01:05,  2.77it/s]\u001b[A\n",
            "\r 40%|████      | 120/300 [00:41<01:06,  2.71it/s]\u001b[A\n",
            "\r 40%|████      | 121/300 [00:41<01:07,  2.66it/s]\u001b[A\n",
            "\r 41%|████      | 122/300 [00:41<01:07,  2.64it/s]\u001b[A\n",
            "\r 41%|████      | 123/300 [00:42<01:05,  2.71it/s]\u001b[A\n",
            "\r 41%|████▏     | 124/300 [00:42<01:04,  2.72it/s]\u001b[A\n",
            "\r 42%|████▏     | 125/300 [00:43<01:03,  2.75it/s]\u001b[A\n",
            "\r 42%|████▏     | 126/300 [00:43<01:01,  2.85it/s]\u001b[A\n",
            "\r 42%|████▏     | 127/300 [00:43<00:58,  2.98it/s]\u001b[A\n",
            "\r 43%|████▎     | 128/300 [00:43<00:55,  3.10it/s]\u001b[A\n",
            "\r 43%|████▎     | 129/300 [00:44<00:53,  3.19it/s]\u001b[A\n",
            "\r 43%|████▎     | 130/300 [00:44<00:53,  3.20it/s]\u001b[A\n",
            "\r 44%|████▎     | 131/300 [00:44<00:53,  3.16it/s]\u001b[A\n",
            "\r 44%|████▍     | 132/300 [00:45<00:53,  3.13it/s]\u001b[A\n",
            "\r 44%|████▍     | 133/300 [00:45<00:55,  3.01it/s]\u001b[A\n",
            "\r 45%|████▍     | 134/300 [00:45<00:55,  3.01it/s]\u001b[A\n",
            "\r 45%|████▌     | 135/300 [00:46<00:56,  2.92it/s]\u001b[A\n",
            "\r 45%|████▌     | 136/300 [00:46<00:57,  2.84it/s]\u001b[A\n",
            "\r 46%|████▌     | 137/300 [00:47<00:58,  2.79it/s]\u001b[A\n",
            "\r 46%|████▌     | 138/300 [00:47<00:57,  2.83it/s]\u001b[A\n",
            "\r 46%|████▋     | 139/300 [00:47<00:56,  2.84it/s]\u001b[A\n",
            "\r 47%|████▋     | 140/300 [00:48<00:54,  2.92it/s]\u001b[A\n",
            "\r 47%|████▋     | 141/300 [00:48<00:53,  2.97it/s]\u001b[A\n",
            "\r 47%|████▋     | 142/300 [00:48<00:51,  3.06it/s]\u001b[A\n",
            "\r 48%|████▊     | 143/300 [00:48<00:52,  3.02it/s]\u001b[A\n",
            "\r 48%|████▊     | 144/300 [00:49<00:52,  2.96it/s]\u001b[A\n",
            "\r 48%|████▊     | 145/300 [00:49<00:52,  2.93it/s]\u001b[A\n",
            "\r 49%|████▊     | 146/300 [00:50<00:53,  2.88it/s]\u001b[A\n",
            "\r 49%|████▉     | 147/300 [00:50<00:51,  2.98it/s]\u001b[A\n",
            "\r 49%|████▉     | 148/300 [00:50<00:51,  2.95it/s]\u001b[A\n",
            "\r 50%|████▉     | 149/300 [00:51<00:52,  2.86it/s]\u001b[A\n",
            "\r 50%|█████     | 150/300 [00:51<00:56,  2.67it/s]\u001b[A\n",
            "\r 50%|█████     | 151/300 [00:51<00:54,  2.75it/s]\u001b[A\n",
            "\r 51%|█████     | 152/300 [00:52<00:53,  2.76it/s]\u001b[A\n",
            "\r 51%|█████     | 153/300 [00:52<00:52,  2.79it/s]\u001b[A\n",
            "\r 51%|█████▏    | 154/300 [00:52<00:50,  2.91it/s]\u001b[A\n",
            "\r 52%|█████▏    | 155/300 [00:53<00:51,  2.83it/s]\u001b[A\n",
            "\r 52%|█████▏    | 156/300 [00:53<00:50,  2.83it/s]\u001b[A\n",
            "\r 52%|█████▏    | 157/300 [00:53<00:48,  2.93it/s]\u001b[A\n",
            "\r 53%|█████▎    | 158/300 [00:54<00:46,  3.04it/s]\u001b[A\n",
            "\r 53%|█████▎    | 159/300 [00:54<00:46,  3.01it/s]\u001b[A\n",
            "\r 53%|█████▎    | 160/300 [00:54<00:45,  3.10it/s]\u001b[A\n",
            "\r 54%|█████▎    | 161/300 [00:55<00:46,  2.99it/s]\u001b[A\n",
            "\r 54%|█████▍    | 162/300 [00:55<00:45,  3.05it/s]\u001b[A\n",
            "\r 54%|█████▍    | 163/300 [00:55<00:46,  2.96it/s]\u001b[A\n",
            "\r 55%|█████▍    | 164/300 [00:56<00:45,  3.02it/s]\u001b[A\n",
            "\r 55%|█████▌    | 165/300 [00:56<00:43,  3.07it/s]\u001b[A\n",
            "\r 55%|█████▌    | 166/300 [00:56<00:45,  2.97it/s]\u001b[A\n",
            "\r 56%|█████▌    | 167/300 [00:57<00:45,  2.92it/s]\u001b[A\n",
            "\r 56%|█████▌    | 168/300 [00:57<00:45,  2.89it/s]\u001b[A\n",
            "\r 56%|█████▋    | 169/300 [00:57<00:44,  2.91it/s]\u001b[A\n",
            "\r 57%|█████▋    | 170/300 [00:58<00:44,  2.89it/s]\u001b[A\n",
            "\r 57%|█████▋    | 171/300 [00:58<00:44,  2.92it/s]\u001b[A\n",
            "\r 57%|█████▋    | 172/300 [00:58<00:44,  2.89it/s]\u001b[A\n",
            "\r 58%|█████▊    | 173/300 [00:59<00:44,  2.86it/s]\u001b[A\n",
            "\r 58%|█████▊    | 174/300 [00:59<00:44,  2.81it/s]\u001b[A\n",
            "\r 58%|█████▊    | 175/300 [01:00<00:44,  2.82it/s]\u001b[A\n",
            "\r 59%|█████▊    | 176/300 [01:00<00:44,  2.76it/s]\u001b[A\n",
            "\r 59%|█████▉    | 177/300 [01:00<00:45,  2.73it/s]\u001b[A\n",
            "\r 59%|█████▉    | 178/300 [01:01<00:45,  2.67it/s]\u001b[A\n",
            "\r 60%|█████▉    | 179/300 [01:01<00:44,  2.69it/s]\u001b[A\n",
            "\r 60%|██████    | 180/300 [01:01<00:43,  2.79it/s]\u001b[A\n",
            "\r 60%|██████    | 181/300 [01:02<00:42,  2.82it/s]\u001b[A\n",
            "\r 61%|██████    | 182/300 [01:02<00:41,  2.83it/s]\u001b[A\n",
            "\r 61%|██████    | 183/300 [01:02<00:39,  2.93it/s]\u001b[A\n",
            "\r 61%|██████▏   | 184/300 [01:03<00:39,  2.97it/s]\u001b[A\n",
            "\r 62%|██████▏   | 185/300 [01:03<00:38,  2.99it/s]\u001b[A\n",
            "\r 62%|██████▏   | 186/300 [01:03<00:37,  3.02it/s]\u001b[A\n",
            "\r 62%|██████▏   | 187/300 [01:04<00:37,  3.03it/s]\u001b[A\n",
            "\r 63%|██████▎   | 188/300 [01:04<00:37,  3.02it/s]\u001b[A\n",
            "\r 63%|██████▎   | 189/300 [01:04<00:37,  2.99it/s]\u001b[A\n",
            "\r 63%|██████▎   | 190/300 [01:05<00:36,  3.04it/s]\u001b[A\n",
            "\r 64%|██████▎   | 191/300 [01:05<00:36,  3.02it/s]\u001b[A\n",
            "\r 64%|██████▍   | 192/300 [01:05<00:36,  2.92it/s]\u001b[A\n",
            "\r 64%|██████▍   | 193/300 [01:06<00:36,  2.94it/s]\u001b[A\n",
            "\r 65%|██████▍   | 194/300 [01:06<00:36,  2.94it/s]\u001b[A\n",
            "\r 65%|██████▌   | 195/300 [01:07<00:38,  2.72it/s]\u001b[A\n",
            "\r 65%|██████▌   | 196/300 [01:07<00:38,  2.68it/s]\u001b[A\n",
            "\r 66%|██████▌   | 197/300 [01:07<00:36,  2.79it/s]\u001b[A\n",
            "\r 66%|██████▌   | 198/300 [01:08<00:36,  2.82it/s]\u001b[A\n",
            "\r 66%|██████▋   | 199/300 [01:08<00:36,  2.79it/s]\u001b[A\n",
            "\r 67%|██████▋   | 200/300 [01:08<00:35,  2.80it/s]\u001b[A\n",
            "\r 67%|██████▋   | 201/300 [01:09<00:34,  2.91it/s]\u001b[A\n",
            "\r 67%|██████▋   | 202/300 [01:09<00:33,  2.93it/s]\u001b[A\n",
            "\r 68%|██████▊   | 203/300 [01:09<00:32,  2.99it/s]\u001b[A\n",
            "\r 68%|██████▊   | 204/300 [01:10<00:32,  2.91it/s]\u001b[A\n",
            "\r 68%|██████▊   | 205/300 [01:10<00:32,  2.96it/s]\u001b[A\n",
            "\r 69%|██████▊   | 206/300 [01:10<00:31,  3.00it/s]\u001b[A\n",
            "\r 69%|██████▉   | 207/300 [01:11<00:31,  2.99it/s]\u001b[A\n",
            "\r 69%|██████▉   | 208/300 [01:11<00:30,  3.01it/s]\u001b[A\n",
            "\r 70%|██████▉   | 209/300 [01:11<00:31,  2.93it/s]\u001b[A\n",
            "\r 70%|███████   | 210/300 [01:12<00:31,  2.81it/s]\u001b[A\n",
            "\r 70%|███████   | 211/300 [01:12<00:30,  2.90it/s]\u001b[A\n",
            "\r 71%|███████   | 212/300 [01:12<00:29,  2.95it/s]\u001b[A\n",
            "\r 71%|███████   | 213/300 [01:13<00:29,  2.90it/s]\u001b[A\n",
            "\r 71%|███████▏  | 214/300 [01:13<00:29,  2.94it/s]\u001b[A\n",
            "\r 72%|███████▏  | 215/300 [01:13<00:28,  3.03it/s]\u001b[A\n",
            "\r 72%|███████▏  | 216/300 [01:14<00:27,  3.04it/s]\u001b[A\n",
            "\r 72%|███████▏  | 217/300 [01:14<00:26,  3.10it/s]\u001b[A\n",
            "\r 73%|███████▎  | 218/300 [01:14<00:26,  3.10it/s]\u001b[A\n",
            "\r 73%|███████▎  | 219/300 [01:15<00:26,  3.06it/s]\u001b[A\n",
            "\r 73%|███████▎  | 220/300 [01:15<00:25,  3.09it/s]\u001b[A\n",
            "\r 74%|███████▎  | 221/300 [01:15<00:25,  3.12it/s]\u001b[A\n",
            "\r 74%|███████▍  | 222/300 [01:16<00:24,  3.18it/s]\u001b[A\n",
            "\r 74%|███████▍  | 223/300 [01:16<00:24,  3.19it/s]\u001b[A\n",
            "\r 75%|███████▍  | 224/300 [01:16<00:24,  3.05it/s]\u001b[A\n",
            "\r 75%|███████▌  | 225/300 [01:17<00:25,  2.96it/s]\u001b[A\n",
            "\r 75%|███████▌  | 226/300 [01:17<00:24,  2.99it/s]\u001b[A\n",
            "\r 76%|███████▌  | 227/300 [01:17<00:24,  3.04it/s]\u001b[A\n",
            "\r 76%|███████▌  | 228/300 [01:18<00:23,  3.07it/s]\u001b[A\n",
            "\r 76%|███████▋  | 229/300 [01:18<00:23,  2.98it/s]\u001b[A\n",
            "\r 77%|███████▋  | 230/300 [01:18<00:23,  2.99it/s]\u001b[A\n",
            "\r 77%|███████▋  | 231/300 [01:19<00:23,  2.92it/s]\u001b[A\n",
            "\r 77%|███████▋  | 232/300 [01:19<00:22,  2.98it/s]\u001b[A\n",
            "\r 78%|███████▊  | 233/300 [01:19<00:22,  3.01it/s]\u001b[A\n",
            "\r 78%|███████▊  | 234/300 [01:20<00:21,  3.09it/s]\u001b[A\n",
            "\r 78%|███████▊  | 235/300 [01:20<00:20,  3.13it/s]\u001b[A\n",
            "\r 79%|███████▊  | 236/300 [01:20<00:20,  3.07it/s]\u001b[A\n",
            "\r 79%|███████▉  | 237/300 [01:21<00:20,  3.07it/s]\u001b[A\n",
            "\r 79%|███████▉  | 238/300 [01:21<00:20,  3.07it/s]\u001b[A\n",
            "\r 80%|███████▉  | 239/300 [01:21<00:20,  2.98it/s]\u001b[A\n",
            "\r 80%|████████  | 240/300 [01:22<00:20,  2.97it/s]\u001b[A\n",
            "\r 80%|████████  | 241/300 [01:22<00:19,  2.97it/s]\u001b[A\n",
            "\r 81%|████████  | 242/300 [01:22<00:20,  2.88it/s]\u001b[A\n",
            "\r 81%|████████  | 243/300 [01:23<00:19,  2.97it/s]\u001b[A\n",
            "\r 81%|████████▏ | 244/300 [01:23<00:19,  2.92it/s]\u001b[A\n",
            "\r 82%|████████▏ | 245/300 [01:23<00:18,  3.00it/s]\u001b[A\n",
            "\r 82%|████████▏ | 246/300 [01:24<00:18,  2.98it/s]\u001b[A\n",
            "\r 82%|████████▏ | 247/300 [01:24<00:18,  2.83it/s]\u001b[A\n",
            "\r 83%|████████▎ | 248/300 [01:24<00:17,  2.90it/s]\u001b[A\n",
            "\r 83%|████████▎ | 249/300 [01:25<00:17,  2.99it/s]\u001b[A\n",
            "\r 83%|████████▎ | 250/300 [01:25<00:16,  2.97it/s]\u001b[A\n",
            "\r 84%|████████▎ | 251/300 [01:25<00:17,  2.86it/s]\u001b[A\n",
            "\r 84%|████████▍ | 252/300 [01:26<00:16,  2.92it/s]\u001b[A\n",
            "\r 84%|████████▍ | 253/300 [01:26<00:16,  2.93it/s]\u001b[A\n",
            "\r 85%|████████▍ | 254/300 [01:26<00:16,  2.86it/s]\u001b[A\n",
            "\r 85%|████████▌ | 255/300 [01:27<00:15,  2.83it/s]\u001b[A\n",
            "\r 85%|████████▌ | 256/300 [01:27<00:15,  2.79it/s]\u001b[A\n",
            "\r 86%|████████▌ | 257/300 [01:27<00:15,  2.81it/s]\u001b[A\n",
            "\r 86%|████████▌ | 258/300 [01:28<00:15,  2.78it/s]\u001b[A\n",
            "\r 86%|████████▋ | 259/300 [01:28<00:14,  2.82it/s]\u001b[A\n",
            "\r 87%|████████▋ | 260/300 [01:29<00:14,  2.80it/s]\u001b[A\n",
            "\r 87%|████████▋ | 261/300 [01:29<00:13,  2.81it/s]\u001b[A\n",
            "\r 87%|████████▋ | 262/300 [01:29<00:13,  2.77it/s]\u001b[A\n",
            "\r 88%|████████▊ | 263/300 [01:30<00:13,  2.70it/s]\u001b[A\n",
            "\r 88%|████████▊ | 264/300 [01:30<00:12,  2.79it/s]\u001b[A\n",
            "\r 88%|████████▊ | 265/300 [01:30<00:12,  2.84it/s]\u001b[A\n",
            "\r 89%|████████▊ | 266/300 [01:31<00:11,  2.84it/s]\u001b[A\n",
            "\r 89%|████████▉ | 267/300 [01:31<00:12,  2.73it/s]\u001b[A\n",
            "\r 89%|████████▉ | 268/300 [01:31<00:11,  2.79it/s]\u001b[A\n",
            "\r 90%|████████▉ | 269/300 [01:32<00:10,  2.90it/s]\u001b[A\n",
            "\r 90%|█████████ | 270/300 [01:32<00:10,  2.93it/s]\u001b[A\n",
            "\r 90%|█████████ | 271/300 [01:32<00:09,  2.97it/s]\u001b[A\n",
            "\r 91%|█████████ | 272/300 [01:33<00:09,  2.86it/s]\u001b[A\n",
            "\r 91%|█████████ | 273/300 [01:33<00:09,  2.96it/s]\u001b[A\n",
            "\r 91%|█████████▏| 274/300 [01:33<00:08,  2.97it/s]\u001b[A\n",
            "\r 92%|█████████▏| 275/300 [01:34<00:08,  2.89it/s]\u001b[A\n",
            "\r 92%|█████████▏| 276/300 [01:34<00:08,  2.83it/s]\u001b[A\n",
            "\r 92%|█████████▏| 277/300 [01:34<00:07,  2.92it/s]\u001b[A\n",
            "\r 93%|█████████▎| 278/300 [01:35<00:07,  3.00it/s]\u001b[A\n",
            "\r 93%|█████████▎| 279/300 [01:35<00:07,  2.99it/s]\u001b[A\n",
            "\r 93%|█████████▎| 280/300 [01:35<00:06,  2.98it/s]\u001b[A\n",
            "\r 94%|█████████▎| 281/300 [01:36<00:06,  2.93it/s]\u001b[A\n",
            "\r 94%|█████████▍| 282/300 [01:36<00:06,  2.82it/s]\u001b[A\n",
            "\r 94%|█████████▍| 283/300 [01:37<00:05,  2.84it/s]\u001b[A\n",
            "\r 95%|█████████▍| 284/300 [01:37<00:05,  2.77it/s]\u001b[A\n",
            "\r 95%|█████████▌| 285/300 [01:37<00:05,  2.86it/s]\u001b[A\n",
            "\r 95%|█████████▌| 286/300 [01:38<00:04,  2.96it/s]\u001b[A\n",
            "\r 96%|█████████▌| 287/300 [01:38<00:04,  2.93it/s]\u001b[A\n",
            "\r 96%|█████████▌| 288/300 [01:38<00:04,  2.94it/s]\u001b[A\n",
            "\r 96%|█████████▋| 289/300 [01:39<00:03,  3.01it/s]\u001b[A\n",
            "\r 97%|█████████▋| 290/300 [01:39<00:03,  2.94it/s]\u001b[A\n",
            "\r 97%|█████████▋| 291/300 [01:39<00:03,  2.99it/s]\u001b[A\n",
            "\r 97%|█████████▋| 292/300 [01:40<00:02,  3.07it/s]\u001b[A\n",
            "\r 98%|█████████▊| 293/300 [01:40<00:02,  2.99it/s]\u001b[A\n",
            "\r 98%|█████████▊| 294/300 [01:40<00:02,  2.99it/s]\u001b[A\n",
            "\r 98%|█████████▊| 295/300 [01:41<00:01,  3.06it/s]\u001b[A\n",
            "\r 99%|█████████▊| 296/300 [01:41<00:01,  3.11it/s]\u001b[A\n",
            "\r 99%|█████████▉| 297/300 [01:41<00:00,  3.16it/s]\u001b[A\n",
            "\r 99%|█████████▉| 298/300 [01:41<00:00,  3.05it/s]\u001b[A\n",
            "\r100%|█████████▉| 299/300 [01:42<00:00,  3.03it/s]\u001b[A\n",
            "\r100%|██████████| 300/300 [01:42<00:00,  2.84it/s]\u001b[A\r                                               \r\n",
            "\r                                                 \r\u001b[A\r 65%|██████▍   | 50/77 [15:38<07:33, 16.81s/it]\n",
            "\r100%|██████████| 300/300 [01:42<00:00,  2.84it/s]\u001b[A\n",
            "\n",
            "\r  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "\n",
            "\n",
            "\r  2%|▏         | 1/50 [00:03<02:31,  3.09s/it]\u001b[A\u001b[A\n",
            "\n",
            "\r  4%|▍         | 2/50 [00:03<01:09,  1.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "\r  6%|▌         | 3/50 [00:03<00:43,  1.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r  8%|▊         | 4/50 [00:04<00:32,  1.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 10%|█         | 5/50 [00:04<00:25,  1.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 12%|█▏        | 6/50 [00:04<00:21,  2.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 14%|█▍        | 7/50 [00:05<00:18,  2.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 16%|█▌        | 8/50 [00:05<00:16,  2.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 18%|█▊        | 9/50 [00:05<00:14,  2.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 20%|██        | 10/50 [00:05<00:14,  2.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 22%|██▏       | 11/50 [00:06<00:13,  2.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 24%|██▍       | 12/50 [00:06<00:12,  2.96it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 26%|██▌       | 13/50 [00:06<00:12,  3.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 28%|██▊       | 14/50 [00:07<00:11,  3.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 30%|███       | 15/50 [00:07<00:10,  3.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 32%|███▏      | 16/50 [00:07<00:10,  3.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 34%|███▍      | 17/50 [00:08<00:10,  3.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 36%|███▌      | 18/50 [00:08<00:10,  3.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 38%|███▊      | 19/50 [00:08<00:09,  3.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 40%|████      | 20/50 [00:09<00:09,  3.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 42%|████▏     | 21/50 [00:09<00:09,  3.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 44%|████▍     | 22/50 [00:09<00:08,  3.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 46%|████▌     | 23/50 [00:10<00:08,  3.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 48%|████▊     | 24/50 [00:10<00:08,  3.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 50%|█████     | 25/50 [00:10<00:08,  3.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 52%|█████▏    | 26/50 [00:11<00:08,  2.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 54%|█████▍    | 27/50 [00:11<00:07,  3.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 56%|█████▌    | 28/50 [00:11<00:07,  3.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 58%|█████▊    | 29/50 [00:12<00:06,  3.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 60%|██████    | 30/50 [00:12<00:06,  3.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 62%|██████▏   | 31/50 [00:12<00:06,  3.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 64%|██████▍   | 32/50 [00:13<00:05,  3.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 66%|██████▌   | 33/50 [00:13<00:05,  3.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 68%|██████▊   | 34/50 [00:13<00:05,  3.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 70%|███████   | 35/50 [00:13<00:04,  3.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 72%|███████▏  | 36/50 [00:14<00:04,  3.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 74%|███████▍  | 37/50 [00:14<00:04,  3.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 76%|███████▌  | 38/50 [00:14<00:03,  3.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 78%|███████▊  | 39/50 [00:15<00:03,  3.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 80%|████████  | 40/50 [00:15<00:03,  3.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 82%|████████▏ | 41/50 [00:15<00:02,  3.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 84%|████████▍ | 42/50 [00:16<00:02,  3.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 86%|████████▌ | 43/50 [00:16<00:02,  3.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 88%|████████▊ | 44/50 [00:16<00:01,  3.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 90%|█████████ | 45/50 [00:17<00:01,  3.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 92%|█████████▏| 46/50 [00:17<00:01,  3.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 94%|█████████▍| 47/50 [00:17<00:00,  3.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 96%|█████████▌| 48/50 [00:18<00:00,  3.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r 98%|█████████▊| 49/50 [00:18<00:00,  3.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "\r100%|██████████| 50/50 [00:18<00:00,  2.92it/s]\u001b[A\u001b[A\r100%|██████████| 50/50 [00:18<00:00,  2.64it/s]\n",
            "\n",
            "\r                                                 \u001b[A\r 66%|██████▌   | 51/77 [16:32<25:28, 58.79s/it]\r 68%|██████▊   | 52/77 [16:48<19:14, 46.18s/it]\r 69%|██████▉   | 53/77 [17:05<14:55, 37.31s/it]\r 70%|███████   | 54/77 [17:21<11:54, 31.06s/it]\r 71%|███████▏  | 55/77 [17:38<09:46, 26.67s/it]\r 73%|███████▎  | 56/77 [17:54<08:16, 23.66s/it]\r 74%|███████▍  | 57/77 [18:11<07:08, 21.43s/it]\r 75%|███████▌  | 58/77 [18:27<06:15, 19.75s/it]\r 77%|███████▋  | 59/77 [18:42<05:34, 18.59s/it]\r 78%|███████▊  | 60/77 [18:59<05:04, 17.89s/it]\r                                               \r\r 78%|███████▊  | 60/77 [18:59<05:04, 17.89s/it]\r 79%|███████▉  | 61/77 [19:15<04:39, 17.46s/it]\r 81%|████████  | 62/77 [19:31<04:14, 16.99s/it]\r 82%|████████▏ | 63/77 [19:48<03:56, 16.90s/it]\r 83%|████████▎ | 64/77 [20:05<03:40, 16.92s/it]\r 84%|████████▍ | 65/77 [20:22<03:24, 17.07s/it]\r 86%|████████▌ | 66/77 [20:39<03:06, 16.91s/it]\r 87%|████████▋ | 67/77 [20:56<02:49, 16.95s/it]\r 88%|████████▊ | 68/77 [21:12<02:30, 16.77s/it]\r 90%|████████▉ | 69/77 [21:29<02:14, 16.77s/it]\r 91%|█████████ | 70/77 [21:45<01:57, 16.72s/it]\r                                               \r\r 91%|█████████ | 70/77 [21:45<01:57, 16.72s/it]\r 92%|█████████▏| 71/77 [22:02<01:40, 16.76s/it]\r 94%|█████████▎| 72/77 [22:18<01:22, 16.55s/it]\r 95%|█████████▍| 73/77 [22:35<01:06, 16.64s/it]\r 96%|█████████▌| 74/77 [22:52<00:49, 16.61s/it]\r 97%|█████████▋| 75/77 [23:08<00:33, 16.55s/it]\r 99%|█████████▊| 76/77 [23:25<00:16, 16.56s/it]\r100%|██████████| 77/77 [23:39<00:00, 16.03s/it]\r                                               \r\r100%|██████████| 77/77 [23:47<00:00, 16.03s/it]\r100%|██████████| 77/77 [23:47<00:00, 18.54s/it]\n",
            "[rank0]:[W221 00:47:15.431562823 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1aBPuzx0eLXS",
        "outputId": "fc31ca03-0194-4c2f-8c98-b9c8fb80d7bf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 96K\n",
            "drwxr-xr-x 6 root root 4.0K Feb 21 00:23 .\n",
            "drwxr-xr-x 5 root root 4.0K Feb 21 00:16 ..\n",
            "-rw-r--r-- 1 root root  783 Feb 21 00:16 config.json\n",
            "drwxr-xr-x 4 root root 4.0K Feb 21 00:23 finetuned_models\n",
            "-rw-r--r-- 1 root root  42K Feb 21 00:16 FinGPT-Assignment1.ipynb\n",
            "drwxr-xr-x 4 root root 4.0K Feb 21 00:19 pretrained-models\n",
            "drwxr-xr-x 2 root root 4.0K Feb 21 00:18 __pycache__\n",
            "-rw-r--r-- 1 root root 8.7K Feb 21 00:18 train_lora.py\n",
            "-rw-r--r-- 1 root root  668 Feb 21 00:16 train.sh\n",
            "-rw-r--r-- 1 root root 5.6K Feb 21 00:16 utils.py\n",
            "drwxr-xr-x 3 root root 4.0K Feb 21 00:23 wandb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -maxdepth 3 -type d -name \"checkpoint-*\"\n",
        "!find . -maxdepth 5 -type f -name \"adapter_*\" -o -name \"*.safetensors\" -o -name \"*.bin\" -o -name \"trainer_state.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rPxns7uWvMen",
        "outputId": "99cb7441-ed11-4e78-d202-9bb0d12f4783"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-50\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-77\n",
            "./finetuned_models/dow30_lora_v1_202602210023/adapter_config.json\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-50/training_args.bin\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-50/adapter_config.json\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-50/trainer_state.json\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-50/adapter_model.safetensors\n",
            "./finetuned_models/dow30_lora_v1_202602210023/adapter_model.safetensors\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-77/training_args.bin\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-77/adapter_config.json\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-77/trainer_state.json\n",
            "./finetuned_models/dow30_lora_v1_202602210023/checkpoint-77/adapter_model.safetensors\n",
            "./pretrained-models/models--deepseek-ai--DeepSeek-R1-Distill-Llama-8B/.no_exist/6a6f4aa4197940add57724a7707d069478df56b1/adapter_config.json\n",
            "./pretrained-models/models--deepseek-ai--DeepSeek-R1-Distill-Llama-8B/.no_exist/6a6f4aa4197940add57724a7707d069478df56b1/model.safetensors\n",
            "./pretrained-models/models--deepseek-ai--DeepSeek-R1-Distill-Llama-8B/snapshots/6a6f4aa4197940add57724a7707d069478df56b1/model-00002-of-000002.safetensors\n",
            "./pretrained-models/models--deepseek-ai--DeepSeek-R1-Distill-Llama-8B/snapshots/6a6f4aa4197940add57724a7707d069478df56b1/model-00001-of-000002.safetensors\n"
          ]
        }
      ]
    }
  ]
}